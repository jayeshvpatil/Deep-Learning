{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">TensorFlow Neural Network Lab</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"image/notmnist.png\">\n",
    "In this lab, you'll use all the tools you learned from *Introduction to TensorFlow* to label images of English letters! The data you are using, <a href=\"http://yaroslavvb.blogspot.com/2011/09/notmnist-dataset.html\">notMNIST</a>, consists of images of a letter from A to J in different fonts.\n",
    "\n",
    "The above images are a few examples of the data you'll be training on. After training the network, you will compare your prediction model against test data. Your goal, by the end of this lab, is to make predictions against that test set with at least an 80% accuracy. Let's jump in!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start this lab, you first need to import all the necessary modules. Run the code below. If it runs successfully, it will print \"`All modules imported`\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All modules imported.\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "import os\n",
    "import pickle\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.utils import resample\n",
    "from tqdm import tqdm\n",
    "from zipfile import ZipFile\n",
    "\n",
    "print('All modules imported.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notMNIST dataset is too large for many computers to handle.  It contains 500,000 images for just training.  You'll be using a subset of this data, 15,000 images for each label (A-J)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files downloaded.\n"
     ]
    }
   ],
   "source": [
    "def download(url, file):\n",
    "    \"\"\"\n",
    "    Download file from <url>\n",
    "    :param url: URL to file\n",
    "    :param file: Local file path\n",
    "    \"\"\"\n",
    "    if not os.path.isfile(file):\n",
    "        print('Downloading ' + file + '...')\n",
    "        urlretrieve(url, file)\n",
    "        print('Download Finished')\n",
    "\n",
    "# Download the training and test dataset.\n",
    "download('https://s3.amazonaws.com/udacity-sdc/notMNIST_train.zip', 'notMNIST_train.zip')\n",
    "download('https://s3.amazonaws.com/udacity-sdc/notMNIST_test.zip', 'notMNIST_test.zip')\n",
    "\n",
    "# Make sure the files aren't corrupted\n",
    "assert hashlib.md5(open('notMNIST_train.zip', 'rb').read()).hexdigest() == 'c8673b3f28f489e9cdf3a3d74e2ac8fa',\\\n",
    "        'notMNIST_train.zip file is corrupted.  Remove the file and try again.'\n",
    "assert hashlib.md5(open('notMNIST_test.zip', 'rb').read()).hexdigest() == '5d3c7e653e63471c88df796156a9dfa9',\\\n",
    "        'notMNIST_test.zip file is corrupted.  Remove the file and try again.'\n",
    "\n",
    "# Wait until you see that all files have been downloaded.\n",
    "print('All files downloaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/210001 [00:00<?, ?files/s]\u001b[A\n",
      "  0%|          | 245/210001 [00:00<01:25, 2449.07files/s]\u001b[A\n",
      "  0%|          | 540/210001 [00:00<01:21, 2580.09files/s]\u001b[A\n",
      "  0%|          | 794/210001 [00:00<01:21, 2566.88files/s]\u001b[A\n",
      "  1%|          | 1113/210001 [00:00<01:16, 2726.39files/s]\u001b[A\n",
      "  1%|          | 1416/210001 [00:00<01:14, 2810.53files/s]\u001b[A\n",
      "  1%|          | 1755/210001 [00:00<01:10, 2961.62files/s]\u001b[A\n",
      "  1%|          | 2047/210001 [00:00<01:10, 2948.48files/s]\u001b[A\n",
      "  1%|          | 2363/210001 [00:00<01:09, 3007.17files/s]\u001b[A\n",
      "  1%|▏         | 2661/210001 [00:00<01:09, 2994.89files/s]\u001b[A\n",
      "  1%|▏         | 2956/210001 [00:01<01:09, 2979.08files/s]\u001b[A\n",
      "  2%|▏         | 3264/210001 [00:01<01:08, 3008.36files/s]\u001b[A\n",
      "  2%|▏         | 3580/210001 [00:01<01:07, 3050.68files/s]\u001b[A\n",
      "  2%|▏         | 3891/210001 [00:01<01:07, 3065.81files/s]\u001b[A\n",
      "  2%|▏         | 4220/210001 [00:01<01:05, 3127.70files/s]\u001b[A\n",
      "  2%|▏         | 4543/210001 [00:01<01:05, 3157.01files/s]\u001b[A\n",
      "  2%|▏         | 4859/210001 [00:01<01:09, 2961.71files/s]\u001b[A\n",
      "  2%|▏         | 5201/210001 [00:01<01:06, 3085.28files/s]\u001b[A\n",
      "  3%|▎         | 5576/210001 [00:01<01:02, 3256.89files/s]\u001b[A\n",
      "  3%|▎         | 5907/210001 [00:01<01:03, 3193.49files/s]\u001b[A\n",
      "  3%|▎         | 6241/210001 [00:02<01:02, 3234.94files/s]\u001b[A\n",
      "  3%|▎         | 6568/210001 [00:02<01:03, 3223.85files/s]\u001b[A\n",
      "  3%|▎         | 6905/210001 [00:02<01:02, 3266.12files/s]\u001b[A\n",
      "  3%|▎         | 7247/210001 [00:02<01:01, 3310.17files/s]\u001b[A\n",
      "  4%|▎         | 7587/210001 [00:02<01:00, 3334.81files/s]\u001b[A\n",
      "  4%|▍         | 7922/210001 [00:02<01:04, 3155.51files/s]\u001b[A\n",
      "  4%|▍         | 8241/210001 [00:02<01:08, 2925.68files/s]\u001b[A\n",
      "  4%|▍         | 8539/210001 [00:02<01:10, 2853.47files/s]\u001b[A\n",
      "  4%|▍         | 8856/210001 [00:02<01:08, 2941.07files/s]\u001b[A\n",
      "  4%|▍         | 9154/210001 [00:03<01:11, 2803.39files/s]\u001b[A\n",
      "  4%|▍         | 9439/210001 [00:03<01:18, 2558.32files/s]\u001b[A\n",
      "  5%|▍         | 9710/210001 [00:03<01:16, 2601.64files/s]\u001b[A\n",
      "  5%|▍         | 9976/210001 [00:03<01:24, 2363.42files/s]\u001b[A\n",
      "  5%|▍         | 10220/210001 [00:03<01:37, 2048.53files/s]\u001b[A\n",
      "  5%|▍         | 10438/210001 [00:03<01:46, 1881.52files/s]\u001b[A\n",
      "  5%|▌         | 10638/210001 [00:03<01:57, 1697.19files/s]\u001b[A\n",
      "  5%|▌         | 10820/210001 [00:03<02:03, 1616.65files/s]\u001b[A\n",
      "  5%|▌         | 10991/210001 [00:04<02:13, 1493.89files/s]\u001b[A\n",
      "  5%|▌         | 11149/210001 [00:04<02:14, 1481.22files/s]\u001b[A\n",
      "  5%|▌         | 11303/210001 [00:04<02:15, 1462.37files/s]\u001b[A\n",
      "  5%|▌         | 11454/210001 [00:04<02:15, 1464.94files/s]\u001b[A\n",
      "  6%|▌         | 11673/210001 [00:04<02:01, 1626.28files/s]\u001b[A\n",
      "  6%|▌         | 11938/210001 [00:04<01:47, 1838.69files/s]\u001b[A\n",
      "  6%|▌         | 12200/210001 [00:04<01:38, 2016.11files/s]\u001b[A\n",
      "  6%|▌         | 12473/210001 [00:04<01:30, 2186.96files/s]\u001b[A\n",
      "  6%|▌         | 12800/210001 [00:04<01:21, 2427.65files/s]\u001b[A\n",
      "  6%|▋         | 13147/210001 [00:05<01:13, 2667.13files/s]\u001b[A\n",
      "  6%|▋         | 13443/210001 [00:05<01:11, 2746.02files/s]\u001b[A\n",
      "  7%|▋         | 13826/210001 [00:05<01:05, 2999.43files/s]\u001b[A\n",
      "  7%|▋         | 14187/210001 [00:05<01:01, 3159.29files/s]\u001b[A\n",
      "  7%|▋         | 14532/210001 [00:05<01:00, 3240.56files/s]\u001b[A\n",
      "  7%|▋         | 14867/210001 [00:05<01:00, 3232.30files/s]\u001b[A\n",
      "  7%|▋         | 15200/210001 [00:05<00:59, 3259.66files/s]\u001b[A\n",
      "  7%|▋         | 15567/210001 [00:05<00:57, 3369.11files/s]\u001b[A\n",
      "  8%|▊         | 15909/210001 [00:05<01:01, 3143.60files/s]\u001b[A\n",
      "  8%|▊         | 16239/210001 [00:05<01:00, 3188.21files/s]\u001b[A\n",
      "  8%|▊         | 16563/210001 [00:06<01:00, 3193.75files/s]\u001b[A\n",
      "  8%|▊         | 16918/210001 [00:06<00:58, 3291.25files/s]\u001b[A\n",
      "  8%|▊         | 17251/210001 [00:06<00:58, 3300.19files/s]\u001b[A\n",
      "  8%|▊         | 17640/210001 [00:06<00:55, 3455.81files/s]\u001b[A\n",
      "  9%|▊         | 17989/210001 [00:06<00:55, 3448.44files/s]\u001b[A\n",
      "  9%|▊         | 18344/210001 [00:06<00:55, 3477.14files/s]\u001b[A\n",
      "  9%|▉         | 18694/210001 [00:06<00:55, 3451.51files/s]\u001b[A\n",
      "  9%|▉         | 19041/210001 [00:06<00:55, 3433.28files/s]\u001b[A\n",
      "  9%|▉         | 19386/210001 [00:06<00:55, 3432.85files/s]\u001b[A\n",
      "  9%|▉         | 19754/210001 [00:06<00:54, 3502.96files/s]\u001b[A\n",
      " 10%|▉         | 20106/210001 [00:07<00:54, 3455.87files/s]\u001b[A\n",
      " 10%|▉         | 20459/210001 [00:07<00:54, 3475.72files/s]\u001b[A\n",
      " 10%|▉         | 20808/210001 [00:07<00:54, 3447.79files/s]\u001b[A\n",
      " 10%|█         | 21185/210001 [00:07<00:53, 3537.78files/s]\u001b[A\n",
      " 10%|█         | 21540/210001 [00:07<00:53, 3534.14files/s]\u001b[A\n",
      " 10%|█         | 21895/210001 [00:07<00:53, 3524.18files/s]\u001b[A\n",
      " 11%|█         | 22248/210001 [00:07<00:54, 3459.55files/s]\u001b[A\n",
      " 11%|█         | 22610/210001 [00:07<00:53, 3504.34files/s]\u001b[A\n",
      " 11%|█         | 22961/210001 [00:07<00:59, 3146.60files/s]\u001b[A\n",
      " 11%|█         | 23316/210001 [00:07<00:57, 3256.70files/s]\u001b[A\n",
      " 11%|█▏        | 23708/210001 [00:08<00:54, 3429.93files/s]\u001b[A\n",
      " 11%|█▏        | 24058/210001 [00:08<00:54, 3415.54files/s]\u001b[A\n",
      " 12%|█▏        | 24415/210001 [00:08<00:53, 3456.64files/s]\u001b[A\n",
      " 12%|█▏        | 24765/210001 [00:08<00:54, 3414.01files/s]\u001b[A\n",
      " 12%|█▏        | 25115/210001 [00:08<00:53, 3433.98files/s]\u001b[A\n",
      " 12%|█▏        | 25467/210001 [00:08<00:53, 3458.13files/s]\u001b[A\n",
      " 12%|█▏        | 25815/210001 [00:08<00:54, 3389.31files/s]\u001b[A\n",
      " 12%|█▏        | 26192/210001 [00:08<00:52, 3490.52files/s]\u001b[A\n",
      " 13%|█▎        | 26543/210001 [00:08<00:52, 3481.87files/s]\u001b[A\n",
      " 13%|█▎        | 26893/210001 [00:09<00:53, 3394.91files/s]\u001b[A\n",
      " 13%|█▎        | 27252/210001 [00:09<00:52, 3448.26files/s]\u001b[A\n",
      " 13%|█▎        | 27598/210001 [00:09<00:53, 3422.52files/s]\u001b[A\n",
      " 13%|█▎        | 27942/210001 [00:09<00:56, 3207.10files/s]\u001b[A\n",
      " 13%|█▎        | 28267/210001 [00:09<00:56, 3193.54files/s]\u001b[A\n",
      " 14%|█▎        | 28629/210001 [00:09<00:54, 3308.59files/s]\u001b[A\n",
      " 14%|█▍        | 28972/210001 [00:09<00:54, 3343.90files/s]\u001b[A\n",
      " 14%|█▍        | 29309/210001 [00:09<00:54, 3315.51files/s]\u001b[A\n",
      " 14%|█▍        | 29658/210001 [00:09<00:53, 3365.99files/s]\u001b[A\n",
      " 14%|█▍        | 30002/210001 [00:09<00:53, 3387.60files/s]\u001b[A\n",
      " 14%|█▍        | 30354/210001 [00:10<00:52, 3424.40files/s]\u001b[A\n",
      " 15%|█▍        | 30698/210001 [00:10<00:52, 3420.64files/s]\u001b[A\n",
      " 15%|█▍        | 31044/210001 [00:10<00:52, 3430.33files/s]\u001b[A\n",
      " 15%|█▍        | 31403/210001 [00:10<00:51, 3475.80files/s]\u001b[A\n",
      " 15%|█▌        | 31751/210001 [00:10<00:52, 3412.74files/s]\u001b[A\n",
      " 15%|█▌        | 32111/210001 [00:10<00:51, 3466.63files/s]\u001b[A\n",
      " 15%|█▌        | 32461/210001 [00:10<00:51, 3475.76files/s]\u001b[A\n",
      " 16%|█▌        | 32809/210001 [00:10<00:51, 3408.45files/s]\u001b[A\n",
      " 16%|█▌        | 33181/210001 [00:10<00:50, 3494.20files/s]\u001b[A\n",
      " 16%|█▌        | 33532/210001 [00:10<00:52, 3372.06files/s]\u001b[A\n",
      " 16%|█▌        | 33871/210001 [00:11<00:52, 3334.54files/s]\u001b[A\n",
      " 16%|█▋        | 34260/210001 [00:11<00:50, 3481.83files/s]\u001b[A\n",
      " 16%|█▋        | 34641/210001 [00:11<00:49, 3566.78files/s]\u001b[A\n",
      " 17%|█▋        | 35000/210001 [00:11<00:49, 3557.21files/s]\u001b[A\n",
      " 17%|█▋        | 35358/210001 [00:11<00:50, 3430.72files/s]\u001b[A\n",
      " 17%|█▋        | 35704/210001 [00:11<00:56, 3066.89files/s]\u001b[A\n",
      " 17%|█▋        | 36020/210001 [00:11<00:58, 2959.43files/s]\u001b[A\n",
      " 17%|█▋        | 36336/210001 [00:11<00:57, 3016.35files/s]\u001b[A\n",
      " 17%|█▋        | 36726/210001 [00:11<00:53, 3234.77files/s]\u001b[A\n",
      " 18%|█▊        | 37058/210001 [00:12<00:56, 3043.26files/s]\u001b[A\n",
      " 18%|█▊        | 37371/210001 [00:12<00:57, 3008.71files/s]\u001b[A\n",
      " 18%|█▊        | 37733/210001 [00:12<00:54, 3165.60files/s]\u001b[A\n",
      " 18%|█▊        | 38071/210001 [00:12<00:53, 3225.11files/s]\u001b[A\n",
      " 18%|█▊        | 38408/210001 [00:12<00:52, 3265.34files/s]\u001b[A\n",
      " 18%|█▊        | 38784/210001 [00:12<00:50, 3398.85files/s]\u001b[A\n",
      " 19%|█▊        | 39128/210001 [00:12<00:50, 3409.73files/s]\u001b[A\n",
      " 19%|█▉        | 39472/210001 [00:12<00:51, 3295.97files/s]\u001b[A\n",
      " 19%|█▉        | 39805/210001 [00:12<00:54, 3108.54files/s]\u001b[A\n",
      " 19%|█▉        | 40120/210001 [00:13<00:57, 2979.39files/s]\u001b[A\n",
      " 19%|█▉        | 40491/210001 [00:13<00:53, 3164.99files/s]\u001b[A\n",
      " 19%|█▉        | 40848/210001 [00:13<00:51, 3275.36files/s]\u001b[A\n",
      " 20%|█▉        | 41181/210001 [00:13<00:52, 3226.90files/s]\u001b[A\n",
      " 20%|█▉        | 41508/210001 [00:13<00:53, 3135.57files/s]\u001b[A\n",
      " 20%|█▉        | 41825/210001 [00:13<00:56, 2985.98files/s]\u001b[A\n",
      " 20%|██        | 42128/210001 [00:13<00:57, 2932.56files/s]\u001b[A\n",
      " 20%|██        | 42425/210001 [00:13<00:58, 2880.57files/s]\u001b[A\n",
      " 20%|██        | 42774/210001 [00:13<00:55, 3038.46files/s]\u001b[A\n",
      " 21%|██        | 43090/210001 [00:13<00:54, 3072.91files/s]\u001b[A\n",
      " 21%|██        | 43464/210001 [00:14<00:51, 3245.29files/s]\u001b[A\n",
      " 21%|██        | 43829/210001 [00:14<00:49, 3356.64files/s]\u001b[A\n",
      " 21%|██        | 44169/210001 [00:14<00:49, 3350.58files/s]\u001b[A\n",
      " 21%|██        | 44515/210001 [00:14<00:48, 3380.42files/s]\u001b[A\n",
      " 21%|██▏       | 44856/210001 [00:14<00:50, 3294.96files/s]\u001b[A\n",
      " 22%|██▏       | 45212/210001 [00:14<00:48, 3369.99files/s]\u001b[A\n",
      " 22%|██▏       | 45574/210001 [00:14<00:47, 3441.27files/s]\u001b[A\n",
      " 22%|██▏       | 45920/210001 [00:14<00:48, 3408.66files/s]\u001b[A\n",
      " 22%|██▏       | 46278/210001 [00:14<00:47, 3458.17files/s]\u001b[A\n",
      " 22%|██▏       | 46625/210001 [00:15<00:47, 3428.62files/s]\u001b[A\n",
      " 22%|██▏       | 46981/210001 [00:15<00:47, 3465.91files/s]\u001b[A\n",
      " 23%|██▎       | 47363/210001 [00:15<00:45, 3565.02files/s]\u001b[A\n",
      " 23%|██▎       | 47721/210001 [00:15<00:45, 3556.32files/s]\u001b[A\n",
      " 23%|██▎       | 48089/210001 [00:15<00:45, 3591.08files/s]\u001b[A\n",
      " 23%|██▎       | 48449/210001 [00:15<00:45, 3584.07files/s]\u001b[A\n",
      " 23%|██▎       | 48808/210001 [00:15<00:46, 3484.26files/s]\u001b[A\n",
      " 23%|██▎       | 49185/210001 [00:15<00:45, 3564.80files/s]\u001b[A\n",
      " 24%|██▎       | 49586/210001 [00:15<00:43, 3687.31files/s]\u001b[A\n",
      " 24%|██▍       | 49968/210001 [00:15<00:42, 3725.17files/s]\u001b[A\n",
      " 24%|██▍       | 50342/210001 [00:16<00:43, 3655.37files/s]\u001b[A\n",
      " 24%|██▍       | 50709/210001 [00:16<00:44, 3547.76files/s]\u001b[A\n",
      " 24%|██▍       | 51066/210001 [00:16<00:45, 3494.96files/s]\u001b[A\n",
      " 25%|██▍       | 51462/210001 [00:16<00:43, 3619.91files/s]\u001b[A\n",
      " 25%|██▍       | 51827/210001 [00:16<00:43, 3626.62files/s]\u001b[A\n",
      " 25%|██▍       | 52194/210001 [00:16<00:43, 3639.53files/s]\u001b[A\n",
      " 25%|██▌       | 52559/210001 [00:16<00:53, 2927.47files/s]\u001b[A\n",
      " 25%|██▌       | 52875/210001 [00:16<00:57, 2718.86files/s]\u001b[A\n",
      " 25%|██▌       | 53166/210001 [00:16<01:01, 2560.58files/s]\u001b[A\n",
      " 25%|██▌       | 53438/210001 [00:17<01:03, 2479.03files/s]\u001b[A\n",
      " 26%|██▌       | 53698/210001 [00:17<01:04, 2410.40files/s]\u001b[A\n",
      " 26%|██▌       | 53948/210001 [00:17<01:04, 2405.26files/s]\u001b[A\n",
      " 26%|██▌       | 54195/210001 [00:17<01:09, 2243.67files/s]\u001b[A\n",
      " 26%|██▌       | 54426/210001 [00:17<01:12, 2139.84files/s]\u001b[A\n",
      " 26%|██▌       | 54664/210001 [00:17<01:10, 2205.84files/s]\u001b[A\n",
      " 26%|██▌       | 54892/210001 [00:17<01:09, 2227.54files/s]\u001b[A\n",
      " 26%|██▌       | 55118/210001 [00:17<01:11, 2160.34files/s]\u001b[A\n",
      " 26%|██▋       | 55337/210001 [00:17<01:11, 2164.41files/s]\u001b[A\n",
      " 26%|██▋       | 55556/210001 [00:18<01:12, 2122.13files/s]\u001b[A\n",
      " 27%|██▋       | 55770/210001 [00:18<01:15, 2053.11files/s]\u001b[A\n",
      " 27%|██▋       | 55999/210001 [00:18<01:12, 2117.68files/s]\u001b[A\n",
      " 27%|██▋       | 56253/210001 [00:18<01:09, 2225.58files/s]\u001b[A\n",
      " 27%|██▋       | 56488/210001 [00:18<01:08, 2252.06files/s]\u001b[A\n",
      " 27%|██▋       | 56719/210001 [00:18<01:07, 2267.78files/s]\u001b[A\n",
      " 27%|██▋       | 56948/210001 [00:18<01:09, 2207.27files/s]\u001b[A\n",
      " 27%|██▋       | 57183/210001 [00:18<01:08, 2246.87files/s]\u001b[A\n",
      " 27%|██▋       | 57431/210001 [00:18<01:06, 2310.53files/s]\u001b[A\n",
      " 27%|██▋       | 57664/210001 [00:19<01:06, 2289.06files/s]\u001b[A\n",
      " 28%|██▊       | 57894/210001 [00:19<01:09, 2194.83files/s]\u001b[A\n",
      " 28%|██▊       | 58115/210001 [00:19<01:10, 2164.46files/s]\u001b[A\n",
      " 28%|██▊       | 58333/210001 [00:19<01:11, 2111.70files/s]\u001b[A\n",
      " 28%|██▊       | 58546/210001 [00:19<01:21, 1851.04files/s]\u001b[A\n",
      " 28%|██▊       | 58764/210001 [00:19<01:18, 1938.06files/s]\u001b[A\n",
      " 28%|██▊       | 58997/210001 [00:19<01:14, 2039.18files/s]\u001b[A\n",
      " 28%|██▊       | 59230/210001 [00:19<01:11, 2108.61files/s]\u001b[A\n",
      " 28%|██▊       | 59454/210001 [00:19<01:10, 2146.20files/s]\u001b[A\n",
      " 28%|██▊       | 59677/210001 [00:20<01:09, 2168.59files/s]\u001b[A\n",
      " 29%|██▊       | 59902/210001 [00:20<01:08, 2189.10files/s]\u001b[A\n",
      " 29%|██▊       | 60136/210001 [00:20<01:07, 2231.02files/s]\u001b[A\n",
      " 29%|██▉       | 60386/210001 [00:20<01:04, 2305.25files/s]\u001b[A\n",
      " 29%|██▉       | 60623/210001 [00:20<01:04, 2323.32files/s]\u001b[A\n",
      " 29%|██▉       | 60877/210001 [00:20<01:02, 2382.92files/s]\u001b[A\n",
      " 29%|██▉       | 61199/210001 [00:20<00:57, 2584.42files/s]\u001b[A\n",
      " 29%|██▉       | 61544/210001 [00:20<00:53, 2793.27files/s]\u001b[A\n",
      " 29%|██▉       | 61899/210001 [00:20<00:49, 2983.79files/s]\u001b[A\n",
      " 30%|██▉       | 62258/210001 [00:20<00:47, 3142.92files/s]\u001b[A\n",
      " 30%|██▉       | 62611/210001 [00:21<00:45, 3247.32files/s]\u001b[A\n",
      " 30%|██▉       | 62944/210001 [00:21<00:49, 2958.81files/s]\u001b[A\n",
      " 30%|███       | 63250/210001 [00:21<00:54, 2669.50files/s]\u001b[A\n",
      " 30%|███       | 63530/210001 [00:21<00:56, 2595.14files/s]\u001b[A\n",
      " 30%|███       | 63799/210001 [00:21<00:59, 2469.58files/s]\u001b[A\n",
      " 31%|███       | 64054/210001 [00:21<01:00, 2427.93files/s]\u001b[A\n",
      " 31%|███       | 64303/210001 [00:21<01:00, 2397.54files/s]\u001b[A\n",
      " 31%|███       | 64557/210001 [00:21<00:59, 2435.13files/s]\u001b[A\n",
      " 31%|███       | 64804/210001 [00:21<01:01, 2365.45files/s]\u001b[A\n",
      " 31%|███       | 65085/210001 [00:22<00:58, 2482.32files/s]\u001b[A\n",
      " 31%|███       | 65337/210001 [00:22<01:02, 2322.00files/s]\u001b[A\n",
      " 31%|███       | 65574/210001 [00:22<01:02, 2296.22files/s]\u001b[A\n",
      " 31%|███▏      | 65807/210001 [00:22<01:04, 2244.55files/s]\u001b[A\n",
      " 31%|███▏      | 66034/210001 [00:22<01:04, 2226.01files/s]\u001b[A\n",
      " 32%|███▏      | 66361/210001 [00:22<00:58, 2459.92files/s]\u001b[A\n",
      " 32%|███▏      | 66692/210001 [00:22<00:53, 2663.80files/s]\u001b[A\n",
      " 32%|███▏      | 67039/210001 [00:22<00:49, 2862.36files/s]\u001b[A\n",
      " 32%|███▏      | 67438/210001 [00:22<00:45, 3126.17files/s]\u001b[A\n",
      " 32%|███▏      | 67800/210001 [00:22<00:43, 3258.34files/s]\u001b[A\n",
      " 32%|███▏      | 68139/210001 [00:23<00:46, 3057.98files/s]\u001b[A\n",
      " 33%|███▎      | 68456/210001 [00:23<00:51, 2757.01files/s]\u001b[A\n",
      " 33%|███▎      | 68746/210001 [00:23<00:50, 2773.96files/s]\u001b[A\n",
      " 33%|███▎      | 69107/210001 [00:23<00:47, 2980.37files/s]\u001b[A\n",
      " 33%|███▎      | 69471/210001 [00:23<00:44, 3150.82files/s]\u001b[A\n",
      " 33%|███▎      | 69800/210001 [00:23<00:43, 3189.67files/s]\u001b[A\n",
      " 33%|███▎      | 70182/210001 [00:23<00:41, 3355.00files/s]\u001b[A\n",
      " 34%|███▎      | 70525/210001 [00:23<00:42, 3268.77files/s]\u001b[A\n",
      " 34%|███▍      | 70905/210001 [00:23<00:40, 3410.07files/s]\u001b[A\n",
      " 34%|███▍      | 71287/210001 [00:24<00:39, 3523.01files/s]\u001b[A\n",
      " 34%|███▍      | 71645/210001 [00:24<00:39, 3508.28files/s]\u001b[A\n",
      " 34%|███▍      | 72028/210001 [00:24<00:38, 3597.91files/s]\u001b[A\n",
      " 34%|███▍      | 72391/210001 [00:24<00:38, 3594.65files/s]\u001b[A\n",
      " 35%|███▍      | 72753/210001 [00:24<00:38, 3573.88files/s]\u001b[A\n",
      " 35%|███▍      | 73125/210001 [00:24<00:37, 3616.46files/s]\u001b[A\n",
      " 35%|███▍      | 73488/210001 [00:24<00:38, 3510.64files/s]\u001b[A\n",
      " 35%|███▌      | 73847/210001 [00:24<00:38, 3531.59files/s]\u001b[A\n",
      " 35%|███▌      | 74212/210001 [00:24<00:38, 3565.61files/s]\u001b[A\n",
      " 36%|███▌      | 74572/210001 [00:24<00:37, 3574.55files/s]\u001b[A\n",
      " 36%|███▌      | 74931/210001 [00:25<00:38, 3546.58files/s]\u001b[A\n",
      " 36%|███▌      | 75297/210001 [00:25<00:37, 3578.94files/s]\u001b[A\n",
      " 36%|███▌      | 75659/210001 [00:25<00:37, 3590.39files/s]\u001b[A\n",
      " 36%|███▌      | 76041/210001 [00:25<00:36, 3655.21files/s]\u001b[A\n",
      " 36%|███▋      | 76412/210001 [00:25<00:36, 3669.70files/s]\u001b[A\n",
      " 37%|███▋      | 76780/210001 [00:25<00:36, 3659.58files/s]\u001b[A\n",
      " 37%|███▋      | 77147/210001 [00:25<00:37, 3584.63files/s]\u001b[A\n",
      " 37%|███▋      | 77537/210001 [00:25<00:36, 3672.57files/s]\u001b[A\n",
      " 37%|███▋      | 77922/210001 [00:25<00:35, 3723.72files/s]\u001b[A\n",
      " 37%|███▋      | 78296/210001 [00:26<00:36, 3641.99files/s]\u001b[A\n",
      " 37%|███▋      | 78683/210001 [00:26<00:35, 3707.13files/s]\u001b[A\n",
      " 38%|███▊      | 79055/210001 [00:26<00:36, 3557.12files/s]\u001b[A\n",
      " 38%|███▊      | 79413/210001 [00:26<00:36, 3560.36files/s]\u001b[A\n",
      " 38%|███▊      | 79771/210001 [00:26<00:37, 3450.16files/s]\u001b[A\n",
      " 38%|███▊      | 80124/210001 [00:26<00:37, 3471.89files/s]\u001b[A\n",
      " 38%|███▊      | 80490/210001 [00:26<00:36, 3524.20files/s]\u001b[A\n",
      " 38%|███▊      | 80844/210001 [00:26<00:38, 3321.37files/s]\u001b[A\n",
      " 39%|███▊      | 81215/210001 [00:26<00:37, 3428.50files/s]\u001b[A\n",
      " 39%|███▉      | 81595/210001 [00:26<00:36, 3531.97files/s]\u001b[A\n",
      " 39%|███▉      | 81991/210001 [00:27<00:35, 3649.13files/s]\u001b[A\n",
      " 39%|███▉      | 82359/210001 [00:27<00:34, 3649.08files/s]\u001b[A\n",
      " 39%|███▉      | 82747/210001 [00:27<00:34, 3713.94files/s]\u001b[A\n",
      " 40%|███▉      | 83121/210001 [00:27<00:34, 3664.13files/s]\u001b[A\n",
      " 40%|███▉      | 83489/210001 [00:27<00:35, 3527.23files/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 83856/210001 [00:27<00:35, 3562.92files/s]\u001b[A\n",
      " 40%|████      | 84227/210001 [00:27<00:34, 3605.09files/s]\u001b[A\n",
      " 40%|████      | 84599/210001 [00:27<00:34, 3636.67files/s]\u001b[A\n",
      " 40%|████      | 84964/210001 [00:27<00:35, 3558.55files/s]\u001b[A\n",
      " 41%|████      | 85342/210001 [00:27<00:34, 3620.78files/s]\u001b[A\n",
      " 41%|████      | 85733/210001 [00:28<00:33, 3702.20files/s]\u001b[A\n",
      " 41%|████      | 86105/210001 [00:28<00:33, 3683.14files/s]\u001b[A\n",
      " 41%|████      | 86475/210001 [00:28<00:33, 3656.80files/s]\u001b[A\n",
      " 41%|████▏     | 86842/210001 [00:28<00:34, 3571.26files/s]\u001b[A\n",
      " 42%|████▏     | 87200/210001 [00:28<00:34, 3571.58files/s]\u001b[A\n",
      " 42%|████▏     | 87571/210001 [00:28<00:33, 3611.80files/s]\u001b[A\n",
      " 42%|████▏     | 87933/210001 [00:28<00:33, 3613.05files/s]\u001b[A\n",
      " 42%|████▏     | 88295/210001 [00:28<00:34, 3491.44files/s]\u001b[A\n",
      " 42%|████▏     | 88658/210001 [00:28<00:34, 3529.19files/s]\u001b[A\n",
      " 42%|████▏     | 89056/210001 [00:29<00:33, 3652.05files/s]\u001b[A\n",
      " 43%|████▎     | 89447/210001 [00:29<00:32, 3725.78files/s]\u001b[A\n",
      " 43%|████▎     | 89822/210001 [00:29<00:33, 3620.10files/s]\u001b[A\n",
      " 43%|████▎     | 90186/210001 [00:29<00:39, 3046.57files/s]\u001b[A\n",
      " 43%|████▎     | 90508/210001 [00:29<00:41, 2912.30files/s]\u001b[A\n",
      " 43%|████▎     | 90878/210001 [00:29<00:38, 3109.80files/s]\u001b[A\n",
      " 43%|████▎     | 91238/210001 [00:29<00:36, 3240.80files/s]\u001b[A\n",
      " 44%|████▎     | 91573/210001 [00:29<00:36, 3226.13files/s]\u001b[A\n",
      " 44%|████▍     | 91903/210001 [00:29<00:36, 3214.41files/s]\u001b[A\n",
      " 44%|████▍     | 92230/210001 [00:30<00:36, 3196.81files/s]\u001b[A\n",
      " 44%|████▍     | 92597/210001 [00:30<00:35, 3320.09files/s]\u001b[A\n",
      " 44%|████▍     | 92969/210001 [00:30<00:34, 3430.17files/s]\u001b[A\n",
      " 44%|████▍     | 93316/210001 [00:30<00:33, 3439.05files/s]\u001b[A\n",
      " 45%|████▍     | 93670/210001 [00:30<00:33, 3468.10files/s]\u001b[A\n",
      " 45%|████▍     | 94036/210001 [00:30<00:32, 3522.40files/s]\u001b[A\n",
      " 45%|████▍     | 94390/210001 [00:30<00:33, 3469.34files/s]\u001b[A\n",
      " 45%|████▌     | 94739/210001 [00:30<00:35, 3218.34files/s]\u001b[A\n",
      " 45%|████▌     | 95066/210001 [00:30<00:40, 2833.95files/s]\u001b[A\n",
      " 45%|████▌     | 95361/210001 [00:31<00:39, 2866.66files/s]\u001b[A\n",
      " 46%|████▌     | 95670/210001 [00:31<00:39, 2927.74files/s]\u001b[A\n",
      " 46%|████▌     | 96026/210001 [00:31<00:36, 3091.99files/s]\u001b[A\n",
      " 46%|████▌     | 96380/210001 [00:31<00:35, 3213.53files/s]\u001b[A\n",
      " 46%|████▌     | 96708/210001 [00:31<00:35, 3205.20files/s]\u001b[A\n",
      " 46%|████▌     | 97075/210001 [00:31<00:33, 3327.96files/s]\u001b[A\n",
      " 46%|████▋     | 97412/210001 [00:31<00:40, 2772.94files/s]\u001b[A\n",
      " 47%|████▋     | 97708/210001 [00:31<00:43, 2581.70files/s]\u001b[A\n",
      " 47%|████▋     | 97982/210001 [00:31<00:43, 2558.47files/s]\u001b[A\n",
      " 47%|████▋     | 98249/210001 [00:32<00:45, 2458.93files/s]\u001b[A\n",
      " 47%|████▋     | 98504/210001 [00:32<00:48, 2300.32files/s]\u001b[A\n",
      " 47%|████▋     | 98743/210001 [00:32<00:48, 2309.62files/s]\u001b[A\n",
      " 47%|████▋     | 98990/210001 [00:32<00:47, 2351.55files/s]\u001b[A\n",
      " 47%|████▋     | 99261/210001 [00:32<00:45, 2444.84files/s]\u001b[A\n",
      " 47%|████▋     | 99510/210001 [00:32<00:47, 2332.64files/s]\u001b[A\n",
      " 47%|████▋     | 99748/210001 [00:32<00:48, 2275.75files/s]\u001b[A\n",
      " 48%|████▊     | 99979/210001 [00:32<00:53, 2073.36files/s]\u001b[A\n",
      " 48%|████▊     | 100199/210001 [00:32<00:52, 2107.39files/s]\u001b[A\n",
      " 48%|████▊     | 100417/210001 [00:33<00:52, 2104.29files/s]\u001b[A\n",
      " 48%|████▊     | 100655/210001 [00:33<00:50, 2162.58files/s]\u001b[A\n",
      " 48%|████▊     | 100895/210001 [00:33<00:48, 2228.20files/s]\u001b[A\n",
      " 48%|████▊     | 101120/210001 [00:33<00:50, 2174.21files/s]\u001b[A\n",
      " 48%|████▊     | 101354/210001 [00:33<00:49, 2217.16files/s]\u001b[A\n",
      " 48%|████▊     | 101578/210001 [00:33<00:49, 2205.01files/s]\u001b[A\n",
      " 48%|████▊     | 101823/210001 [00:33<00:47, 2272.93files/s]\u001b[A\n",
      " 49%|████▊     | 102070/210001 [00:33<00:46, 2327.95files/s]\u001b[A\n",
      " 49%|████▊     | 102305/210001 [00:33<00:47, 2280.60files/s]\u001b[A\n",
      " 49%|████▉     | 102535/210001 [00:33<00:47, 2248.99files/s]\u001b[A\n",
      " 49%|████▉     | 102761/210001 [00:34<00:48, 2195.42files/s]\u001b[A\n",
      " 49%|████▉     | 103004/210001 [00:34<00:47, 2256.85files/s]\u001b[A\n",
      " 49%|████▉     | 103231/210001 [00:34<00:47, 2255.37files/s]\u001b[A\n",
      " 49%|████▉     | 103458/210001 [00:34<00:48, 2178.25files/s]\u001b[A\n",
      " 49%|████▉     | 103768/210001 [00:34<00:44, 2390.26files/s]\u001b[A\n",
      " 50%|████▉     | 104015/210001 [00:34<00:46, 2292.78files/s]\u001b[A\n",
      " 50%|████▉     | 104251/210001 [00:34<00:47, 2217.84files/s]\u001b[A\n",
      " 50%|████▉     | 104490/210001 [00:34<00:46, 2263.63files/s]\u001b[A\n",
      " 50%|████▉     | 104813/210001 [00:34<00:42, 2486.42files/s]\u001b[A\n",
      " 50%|█████     | 105170/210001 [00:35<00:38, 2734.52files/s]\u001b[A\n",
      " 50%|█████     | 105458/210001 [00:35<00:40, 2598.16files/s]\u001b[A\n",
      " 50%|█████     | 105729/210001 [00:35<00:42, 2425.15files/s]\u001b[A\n",
      " 50%|█████     | 105982/210001 [00:35<00:43, 2391.44files/s]\u001b[A\n",
      " 51%|█████     | 106229/210001 [00:35<00:44, 2315.76files/s]\u001b[A\n",
      " 51%|█████     | 106517/210001 [00:35<00:42, 2459.65files/s]\u001b[A\n",
      " 51%|█████     | 106855/210001 [00:35<00:38, 2678.04files/s]\u001b[A\n",
      " 51%|█████     | 107172/210001 [00:35<00:36, 2807.96files/s]\u001b[A\n",
      " 51%|█████     | 107462/210001 [00:35<00:38, 2661.92files/s]\u001b[A\n",
      " 51%|█████▏    | 107736/210001 [00:36<00:38, 2631.13files/s]\u001b[A\n",
      " 51%|█████▏    | 108094/210001 [00:36<00:35, 2857.18files/s]\u001b[A\n",
      " 52%|█████▏    | 108390/210001 [00:36<00:36, 2756.47files/s]\u001b[A\n",
      " 52%|█████▏    | 108674/210001 [00:36<00:38, 2610.46files/s]\u001b[A\n",
      " 52%|█████▏    | 108942/210001 [00:36<00:41, 2459.43files/s]\u001b[A\n",
      " 52%|█████▏    | 109195/210001 [00:36<00:42, 2391.13files/s]\u001b[A\n",
      " 52%|█████▏    | 109443/210001 [00:36<00:41, 2412.99files/s]\u001b[A\n",
      " 52%|█████▏    | 109688/210001 [00:36<00:43, 2311.42files/s]\u001b[A\n",
      " 52%|█████▏    | 109939/210001 [00:36<00:42, 2365.45files/s]\u001b[A\n",
      " 52%|█████▏    | 110179/210001 [00:37<00:43, 2311.48files/s]\u001b[A\n",
      " 53%|█████▎    | 110413/210001 [00:37<00:44, 2253.22files/s]\u001b[A\n",
      " 53%|█████▎    | 110641/210001 [00:37<00:44, 2212.44files/s]\u001b[A\n",
      " 53%|█████▎    | 110869/210001 [00:37<00:44, 2230.14files/s]\u001b[A\n",
      " 53%|█████▎    | 111136/210001 [00:37<00:42, 2344.87files/s]\u001b[A\n",
      " 53%|█████▎    | 111473/210001 [00:37<00:38, 2579.47files/s]\u001b[A\n",
      " 53%|█████▎    | 111740/210001 [00:37<00:38, 2583.07files/s]\u001b[A\n",
      " 53%|█████▎    | 112005/210001 [00:37<00:39, 2458.56files/s]\u001b[A\n",
      " 53%|█████▎    | 112257/210001 [00:37<00:39, 2462.63files/s]\u001b[A\n",
      " 54%|█████▎    | 112509/210001 [00:37<00:39, 2472.33files/s]\u001b[A\n",
      " 54%|█████▎    | 112759/210001 [00:38<00:39, 2444.34files/s]\u001b[A\n",
      " 54%|█████▍    | 113006/210001 [00:38<00:39, 2441.93files/s]\u001b[A\n",
      " 54%|█████▍    | 113257/210001 [00:38<00:39, 2461.59files/s]\u001b[A\n",
      " 54%|█████▍    | 113505/210001 [00:38<00:40, 2389.35files/s]\u001b[A\n",
      " 54%|█████▍    | 113778/210001 [00:38<00:38, 2481.21files/s]\u001b[A\n",
      " 54%|█████▍    | 114122/210001 [00:38<00:35, 2707.06files/s]\u001b[A\n",
      " 55%|█████▍    | 114475/210001 [00:38<00:32, 2910.58files/s]\u001b[A\n",
      " 55%|█████▍    | 114823/210001 [00:38<00:31, 3060.77files/s]\u001b[A\n",
      " 55%|█████▍    | 115210/210001 [00:38<00:29, 3265.62files/s]\u001b[A\n",
      " 55%|█████▌    | 115547/210001 [00:39<00:30, 3090.62files/s]\u001b[A\n",
      " 55%|█████▌    | 115865/210001 [00:39<00:31, 2965.16files/s]\u001b[A\n",
      " 55%|█████▌    | 116169/210001 [00:39<00:32, 2852.19files/s]\u001b[A\n",
      " 55%|█████▌    | 116504/210001 [00:39<00:31, 2983.73files/s]\u001b[A\n",
      " 56%|█████▌    | 116906/210001 [00:39<00:28, 3232.66files/s]\u001b[A\n",
      " 56%|█████▌    | 117262/210001 [00:39<00:27, 3324.15files/s]\u001b[A\n",
      " 56%|█████▌    | 117603/210001 [00:39<00:27, 3332.52files/s]\u001b[A\n",
      " 56%|█████▌    | 117961/210001 [00:39<00:27, 3402.70files/s]\u001b[A\n",
      " 56%|█████▋    | 118325/210001 [00:39<00:26, 3469.42files/s]\u001b[A\n",
      " 57%|█████▋    | 118676/210001 [00:39<00:26, 3472.29files/s]\u001b[A\n",
      " 57%|█████▋    | 119088/210001 [00:40<00:24, 3643.88files/s]\u001b[A\n",
      " 57%|█████▋    | 119457/210001 [00:40<00:24, 3648.65files/s]\u001b[A\n",
      " 57%|█████▋    | 119864/210001 [00:40<00:23, 3763.68files/s]\u001b[A\n",
      " 57%|█████▋    | 120260/210001 [00:40<00:23, 3819.72files/s]\u001b[A\n",
      " 57%|█████▋    | 120645/210001 [00:40<00:24, 3683.56files/s]\u001b[A\n",
      " 58%|█████▊    | 121016/210001 [00:40<00:24, 3673.08files/s]\u001b[A\n",
      " 58%|█████▊    | 121413/210001 [00:40<00:23, 3756.01files/s]\u001b[A\n",
      " 58%|█████▊    | 121791/210001 [00:40<00:23, 3710.33files/s]\u001b[A\n",
      " 58%|█████▊    | 122173/210001 [00:40<00:23, 3740.59files/s]\u001b[A\n",
      " 58%|█████▊    | 122549/210001 [00:40<00:24, 3625.33files/s]\u001b[A\n",
      " 59%|█████▊    | 122944/210001 [00:41<00:23, 3715.73files/s]\u001b[A\n",
      " 59%|█████▊    | 123318/210001 [00:41<00:24, 3525.29files/s]\u001b[A\n",
      " 59%|█████▉    | 123693/210001 [00:41<00:24, 3589.48files/s]\u001b[A\n",
      " 59%|█████▉    | 124055/210001 [00:41<00:23, 3598.20files/s]\u001b[A\n",
      " 59%|█████▉    | 124421/210001 [00:41<00:23, 3615.10files/s]\u001b[A\n",
      " 59%|█████▉    | 124786/210001 [00:41<00:23, 3623.68files/s]\u001b[A\n",
      " 60%|█████▉    | 125171/210001 [00:41<00:23, 3686.77files/s]\u001b[A\n",
      " 60%|█████▉    | 125541/210001 [00:41<00:23, 3612.95files/s]\u001b[A\n",
      " 60%|█████▉    | 125904/210001 [00:41<00:23, 3593.14files/s]\u001b[A\n",
      " 60%|██████    | 126265/210001 [00:42<00:23, 3594.81files/s]\u001b[A\n",
      " 60%|██████    | 126625/210001 [00:42<00:23, 3541.86files/s]\u001b[A\n",
      " 60%|██████    | 127018/210001 [00:42<00:22, 3649.79files/s]\u001b[A\n",
      " 61%|██████    | 127390/210001 [00:42<00:22, 3669.60files/s]\u001b[A\n",
      " 61%|██████    | 127773/210001 [00:42<00:22, 3713.16files/s]\u001b[A\n",
      " 61%|██████    | 128146/210001 [00:42<00:22, 3587.43files/s]\u001b[A\n",
      " 61%|██████    | 128507/210001 [00:42<00:25, 3221.92files/s]\u001b[A\n",
      " 61%|██████▏   | 128838/210001 [00:42<00:25, 3210.51files/s]\u001b[A\n",
      " 62%|██████▏   | 129168/210001 [00:42<00:24, 3233.57files/s]\u001b[A\n",
      " 62%|██████▏   | 129511/210001 [00:42<00:24, 3288.72files/s]\u001b[A\n",
      " 62%|██████▏   | 129855/210001 [00:43<00:24, 3331.47files/s]\u001b[A\n",
      " 62%|██████▏   | 130191/210001 [00:43<00:24, 3250.74files/s]\u001b[A\n",
      " 62%|██████▏   | 130519/210001 [00:43<00:25, 3085.82files/s]\u001b[A\n",
      " 62%|██████▏   | 130841/210001 [00:43<00:25, 3123.48files/s]\u001b[A\n",
      " 62%|██████▏   | 131171/210001 [00:43<00:24, 3174.37files/s]\u001b[A\n",
      " 63%|██████▎   | 131491/210001 [00:43<00:27, 2851.64files/s]\u001b[A\n",
      " 63%|██████▎   | 131784/210001 [00:43<00:29, 2628.44files/s]\u001b[A\n",
      " 63%|██████▎   | 132176/210001 [00:43<00:26, 2915.44files/s]\u001b[A\n",
      " 63%|██████▎   | 132552/210001 [00:43<00:24, 3124.94files/s]\u001b[A\n",
      " 63%|██████▎   | 132941/210001 [00:44<00:23, 3320.72files/s]\u001b[A\n",
      " 63%|██████▎   | 133305/210001 [00:44<00:22, 3409.93files/s]\u001b[A\n",
      " 64%|██████▎   | 133657/210001 [00:44<00:23, 3288.08files/s]\u001b[A\n",
      " 64%|██████▍   | 133995/210001 [00:44<00:23, 3218.87files/s]\u001b[A\n",
      " 64%|██████▍   | 134323/210001 [00:44<00:24, 3109.05files/s]\u001b[A\n",
      " 64%|██████▍   | 134639/210001 [00:44<00:24, 3067.09files/s]\u001b[A\n",
      " 64%|██████▍   | 134950/210001 [00:44<00:25, 2976.98files/s]\u001b[A\n",
      " 64%|██████▍   | 135251/210001 [00:44<00:25, 2891.22files/s]\u001b[A\n",
      " 65%|██████▍   | 135543/210001 [00:44<00:25, 2894.64files/s]\u001b[A\n",
      " 65%|██████▍   | 135870/210001 [00:45<00:24, 2997.53files/s]\u001b[A\n",
      " 65%|██████▍   | 136173/210001 [00:45<00:24, 3003.91files/s]\u001b[A\n",
      " 65%|██████▍   | 136475/210001 [00:45<00:24, 2943.94files/s]\u001b[A\n",
      " 65%|██████▌   | 136784/210001 [00:45<00:24, 2984.39files/s]\u001b[A\n",
      " 65%|██████▌   | 137084/210001 [00:45<00:24, 2920.55files/s]\u001b[A\n",
      " 65%|██████▌   | 137397/210001 [00:45<00:24, 2977.39files/s]\u001b[A\n",
      " 66%|██████▌   | 137708/210001 [00:45<00:23, 3014.83files/s]\u001b[A\n",
      " 66%|██████▌   | 138011/210001 [00:45<00:25, 2839.76files/s]\u001b[A\n",
      " 66%|██████▌   | 138298/210001 [00:45<00:26, 2751.64files/s]\u001b[A\n",
      " 66%|██████▌   | 138576/210001 [00:46<00:26, 2713.06files/s]\u001b[A\n",
      " 66%|██████▌   | 138880/210001 [00:46<00:25, 2799.99files/s]\u001b[A\n",
      " 66%|██████▋   | 139201/210001 [00:46<00:24, 2906.25files/s]\u001b[A\n",
      " 66%|██████▋   | 139495/210001 [00:46<00:24, 2885.76files/s]\u001b[A\n",
      " 67%|██████▋   | 139812/210001 [00:46<00:23, 2959.76files/s]\u001b[A\n",
      " 67%|██████▋   | 140199/210001 [00:46<00:21, 3183.69files/s]\u001b[A\n",
      " 67%|██████▋   | 140540/210001 [00:46<00:21, 3244.78files/s]\u001b[A\n",
      " 67%|██████▋   | 140869/210001 [00:46<00:31, 2185.05files/s]\u001b[A\n",
      " 67%|██████▋   | 141137/210001 [00:47<00:32, 2124.59files/s]\u001b[A\n",
      " 67%|██████▋   | 141395/210001 [00:47<00:30, 2242.49files/s]\u001b[A\n",
      " 67%|██████▋   | 141673/210001 [00:47<00:28, 2377.31files/s]\u001b[A\n",
      " 68%|██████▊   | 141932/210001 [00:47<00:28, 2381.17files/s]\u001b[A\n",
      " 68%|██████▊   | 142185/210001 [00:47<00:34, 1979.26files/s]\u001b[A\n",
      " 68%|██████▊   | 142536/210001 [00:47<00:29, 2276.55files/s]\u001b[A\n",
      " 68%|██████▊   | 142795/210001 [00:47<00:29, 2263.14files/s]\u001b[A\n",
      " 68%|██████▊   | 143044/210001 [00:47<00:30, 2168.55files/s]\u001b[A\n",
      " 68%|██████▊   | 143316/210001 [00:47<00:28, 2304.51files/s]\u001b[A\n",
      " 68%|██████▊   | 143618/210001 [00:48<00:26, 2477.87files/s]\u001b[A\n",
      " 69%|██████▊   | 143879/210001 [00:48<00:27, 2365.71files/s]\u001b[A\n",
      " 69%|██████▊   | 144165/210001 [00:48<00:26, 2493.15files/s]\u001b[A\n",
      " 69%|██████▉   | 144488/210001 [00:48<00:24, 2673.10files/s]\u001b[A\n",
      " 69%|██████▉   | 144766/210001 [00:48<00:25, 2528.58files/s]\u001b[A\n",
      " 69%|██████▉   | 145028/210001 [00:48<00:26, 2422.20files/s]\u001b[A\n",
      " 69%|██████▉   | 145278/210001 [00:48<00:28, 2292.24files/s]\u001b[A\n",
      " 69%|██████▉   | 145514/210001 [00:48<00:29, 2221.30files/s]\u001b[A\n",
      " 69%|██████▉   | 145742/210001 [00:48<00:30, 2136.02files/s]\u001b[A\n",
      " 70%|██████▉   | 146017/210001 [00:49<00:27, 2286.16files/s]\u001b[A\n",
      " 70%|██████▉   | 146323/210001 [00:49<00:25, 2473.01files/s]\u001b[A\n",
      " 70%|██████▉   | 146591/210001 [00:49<00:25, 2530.54files/s]\u001b[A\n",
      " 70%|██████▉   | 146851/210001 [00:49<00:25, 2456.15files/s]\u001b[A\n",
      " 70%|███████   | 147102/210001 [00:49<00:25, 2423.50files/s]\u001b[A\n",
      " 70%|███████   | 147393/210001 [00:49<00:24, 2551.00files/s]\u001b[A\n",
      " 70%|███████   | 147715/210001 [00:49<00:22, 2720.34files/s]\u001b[A\n",
      " 70%|███████   | 148024/210001 [00:49<00:21, 2817.41files/s]\u001b[A\n",
      " 71%|███████   | 148319/210001 [00:49<00:21, 2853.96files/s]\u001b[A\n",
      " 71%|███████   | 148609/210001 [00:50<00:23, 2650.21files/s]\u001b[A\n",
      " 71%|███████   | 148880/210001 [00:50<00:24, 2494.47files/s]\u001b[A\n",
      " 71%|███████   | 149203/210001 [00:50<00:22, 2676.55files/s]\u001b[A\n",
      " 71%|███████   | 149557/210001 [00:50<00:20, 2887.60files/s]\u001b[A\n",
      " 71%|███████▏  | 149924/210001 [00:50<00:19, 3084.08files/s]\u001b[A\n",
      " 72%|███████▏  | 150244/210001 [00:50<00:21, 2829.46files/s]\u001b[A\n",
      " 72%|███████▏  | 150539/210001 [00:50<00:21, 2789.58files/s]\u001b[A\n",
      " 72%|███████▏  | 150827/210001 [00:50<00:21, 2808.44files/s]\u001b[A\n",
      " 72%|███████▏  | 151173/210001 [00:50<00:19, 2974.26files/s]\u001b[A\n",
      " 72%|███████▏  | 151561/210001 [00:50<00:18, 3198.04files/s]\u001b[A\n",
      " 72%|███████▏  | 151891/210001 [00:51<00:18, 3143.15files/s]\u001b[A\n",
      " 72%|███████▏  | 152219/210001 [00:51<00:18, 3180.81files/s]\u001b[A\n",
      " 73%|███████▎  | 152609/210001 [00:51<00:17, 3366.85files/s]\u001b[A\n",
      " 73%|███████▎  | 152981/210001 [00:51<00:16, 3463.37files/s]\u001b[A\n",
      " 73%|███████▎  | 153333/210001 [00:51<00:18, 2991.87files/s]\u001b[A\n",
      " 73%|███████▎  | 153648/210001 [00:51<00:20, 2719.16files/s]\u001b[A\n",
      " 73%|███████▎  | 154008/210001 [00:51<00:19, 2933.55files/s]\u001b[A\n",
      " 74%|███████▎  | 154376/210001 [00:51<00:17, 3123.38files/s]\u001b[A\n",
      " 74%|███████▎  | 154755/210001 [00:51<00:16, 3297.15files/s]\u001b[A\n",
      " 74%|███████▍  | 155125/210001 [00:52<00:16, 3408.19files/s]\u001b[A\n",
      " 74%|███████▍  | 155519/210001 [00:52<00:15, 3551.03files/s]\u001b[A\n",
      " 74%|███████▍  | 155903/210001 [00:52<00:14, 3632.60files/s]\u001b[A\n",
      " 74%|███████▍  | 156275/210001 [00:52<00:14, 3655.30files/s]\u001b[A\n",
      " 75%|███████▍  | 156645/210001 [00:52<00:15, 3537.98files/s]\u001b[A\n",
      " 75%|███████▍  | 157028/210001 [00:52<00:14, 3620.27files/s]\u001b[A\n",
      " 75%|███████▍  | 157394/210001 [00:52<00:15, 3484.10files/s]\u001b[A\n",
      " 75%|███████▌  | 157746/210001 [00:52<00:15, 3322.83files/s]\u001b[A\n",
      " 75%|███████▌  | 158112/210001 [00:52<00:15, 3416.19files/s]\u001b[A\n",
      " 75%|███████▌  | 158499/210001 [00:53<00:14, 3538.92files/s]\u001b[A\n",
      " 76%|███████▌  | 158857/210001 [00:53<00:14, 3448.88files/s]\u001b[A\n",
      " 76%|███████▌  | 159205/210001 [00:53<00:14, 3453.68files/s]\u001b[A\n",
      " 76%|███████▌  | 159611/210001 [00:53<00:13, 3613.80files/s]\u001b[A\n",
      " 76%|███████▌  | 160031/210001 [00:53<00:13, 3770.33files/s]\u001b[A\n",
      " 76%|███████▋  | 160413/210001 [00:53<00:13, 3709.95files/s]\u001b[A\n",
      " 77%|███████▋  | 160792/210001 [00:53<00:13, 3733.31files/s]\u001b[A\n",
      " 77%|███████▋  | 161168/210001 [00:53<00:13, 3577.92files/s]\u001b[A\n",
      " 77%|███████▋  | 161529/210001 [00:53<00:15, 3132.37files/s]\u001b[A\n",
      " 77%|███████▋  | 161855/210001 [00:54<00:15, 3038.92files/s]\u001b[A\n",
      " 77%|███████▋  | 162168/210001 [00:54<00:16, 2954.16files/s]\u001b[A\n",
      " 77%|███████▋  | 162471/210001 [00:54<00:16, 2797.58files/s]\u001b[A\n",
      " 78%|███████▊  | 162758/210001 [00:54<00:41, 1130.73files/s]\u001b[A\n",
      " 78%|███████▊  | 162973/210001 [00:55<00:40, 1174.89files/s]\u001b[A\n",
      " 78%|███████▊  | 163163/210001 [00:55<00:35, 1321.02files/s]\u001b[A\n",
      " 78%|███████▊  | 163418/210001 [00:55<00:30, 1540.43files/s]\u001b[A\n",
      " 78%|███████▊  | 163691/210001 [00:55<00:26, 1771.90files/s]\u001b[A\n",
      " 78%|███████▊  | 163958/210001 [00:55<00:23, 1970.62files/s]\u001b[A\n",
      " 78%|███████▊  | 164226/210001 [00:55<00:21, 2140.47files/s]\u001b[A\n",
      " 78%|███████▊  | 164561/210001 [00:55<00:18, 2398.44files/s]\u001b[A\n",
      " 79%|███████▊  | 164855/210001 [00:55<00:17, 2538.17files/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 165156/210001 [00:55<00:16, 2659.89files/s]\u001b[A\n",
      " 79%|███████▉  | 165442/210001 [00:55<00:17, 2583.36files/s]\u001b[A\n",
      " 79%|███████▉  | 165729/210001 [00:56<00:16, 2662.54files/s]\u001b[A\n",
      " 79%|███████▉  | 166006/210001 [00:56<00:17, 2515.04files/s]\u001b[A\n",
      " 79%|███████▉  | 166267/210001 [00:56<00:20, 2166.42files/s]\u001b[A\n",
      " 79%|███████▉  | 166499/210001 [00:56<00:30, 1417.23files/s]\u001b[A\n",
      " 79%|███████▉  | 166685/210001 [00:56<00:31, 1387.24files/s]\u001b[A\n",
      " 79%|███████▉  | 166855/210001 [00:56<00:29, 1444.83files/s]\u001b[A\n",
      " 80%|███████▉  | 167030/210001 [00:56<00:28, 1503.81files/s]\u001b[A\n",
      " 80%|███████▉  | 167197/210001 [00:57<00:32, 1304.72files/s]\u001b[A\n",
      " 80%|███████▉  | 167344/210001 [00:57<00:42, 1012.87files/s]\u001b[A\n",
      " 80%|███████▉  | 167467/210001 [00:57<00:56, 753.54files/s] \u001b[A\n",
      " 80%|███████▉  | 167622/210001 [00:57<00:47, 890.48files/s]\u001b[A\n",
      " 80%|███████▉  | 167794/210001 [00:57<00:40, 1040.33files/s]\u001b[A\n",
      " 80%|███████▉  | 167976/210001 [00:57<00:35, 1193.33files/s]\u001b[A\n",
      " 80%|████████  | 168124/210001 [00:58<00:51, 816.45files/s] \u001b[A\n",
      " 80%|████████  | 168242/210001 [00:58<00:53, 785.86files/s]\u001b[A\n",
      " 80%|████████  | 168356/210001 [00:58<00:48, 850.74files/s]\u001b[A\n",
      " 80%|████████  | 168514/210001 [00:58<00:42, 982.27files/s]\u001b[A\n",
      " 80%|████████  | 168634/210001 [00:58<00:49, 833.23files/s]\u001b[A\n",
      " 80%|████████  | 168855/210001 [00:58<00:40, 1024.66files/s]\u001b[A\n",
      " 81%|████████  | 169086/210001 [00:59<00:33, 1229.57files/s]\u001b[A\n",
      " 81%|████████  | 169252/210001 [00:59<00:30, 1327.20files/s]\u001b[A\n",
      " 81%|████████  | 169417/210001 [00:59<01:02, 647.95files/s] \u001b[A\n",
      " 81%|████████  | 169542/210001 [00:59<01:01, 654.58files/s]\u001b[A\n",
      " 81%|████████  | 169650/210001 [01:00<01:17, 519.75files/s]\u001b[A\n",
      " 81%|████████  | 169736/210001 [01:00<01:23, 479.49files/s]\u001b[A\n",
      " 81%|████████  | 169808/210001 [01:00<01:18, 512.19files/s]\u001b[A\n",
      " 81%|████████  | 169877/210001 [01:00<01:18, 510.94files/s]\u001b[A\n",
      " 81%|████████  | 169947/210001 [01:00<01:12, 553.18files/s]\u001b[A\n",
      " 81%|████████  | 170012/210001 [01:00<01:18, 508.38files/s]\u001b[A\n",
      " 81%|████████  | 170071/210001 [01:01<01:18, 507.03files/s]\u001b[A\n",
      " 81%|████████  | 170178/210001 [01:01<01:06, 601.82files/s]\u001b[A\n",
      " 81%|████████  | 170250/210001 [01:01<01:04, 619.67files/s]\u001b[A\n",
      " 81%|████████  | 170397/210001 [01:01<00:52, 749.58files/s]\u001b[A\n",
      " 81%|████████  | 170561/210001 [01:01<00:44, 895.40files/s]\u001b[A\n",
      " 81%|████████▏ | 170744/210001 [01:01<00:37, 1056.86files/s]\u001b[A\n",
      " 81%|████████▏ | 170941/210001 [01:01<00:31, 1227.31files/s]\u001b[A\n",
      " 81%|████████▏ | 171114/210001 [01:01<00:28, 1343.80files/s]\u001b[A\n",
      " 82%|████████▏ | 171316/210001 [01:01<00:25, 1491.91files/s]\u001b[A\n",
      " 82%|████████▏ | 171488/210001 [01:01<00:27, 1383.60files/s]\u001b[A\n",
      " 82%|████████▏ | 171656/210001 [01:02<00:26, 1459.84files/s]\u001b[A\n",
      " 82%|████████▏ | 171936/210001 [01:02<00:22, 1704.49files/s]\u001b[A\n",
      " 82%|████████▏ | 172132/210001 [01:02<00:29, 1292.01files/s]\u001b[A\n",
      " 82%|████████▏ | 172294/210001 [01:02<00:45, 837.50files/s] \u001b[A\n",
      " 82%|████████▏ | 172437/210001 [01:02<00:39, 951.04files/s]\u001b[A\n",
      " 82%|████████▏ | 172568/210001 [01:02<00:37, 988.05files/s]\u001b[A\n",
      " 82%|████████▏ | 172692/210001 [01:03<00:38, 975.56files/s]\u001b[A\n",
      " 82%|████████▏ | 172808/210001 [01:03<00:38, 960.40files/s]\u001b[A\n",
      " 82%|████████▏ | 172917/210001 [01:03<00:49, 742.16files/s]\u001b[A\n",
      " 82%|████████▏ | 173008/210001 [01:03<00:50, 735.14files/s]\u001b[A\n",
      " 82%|████████▏ | 173145/210001 [01:03<00:43, 853.25files/s]\u001b[A\n",
      " 83%|████████▎ | 173379/210001 [01:03<00:34, 1054.17files/s]\u001b[A\n",
      " 83%|████████▎ | 173592/210001 [01:03<00:29, 1242.17files/s]\u001b[A\n",
      " 83%|████████▎ | 173820/210001 [01:03<00:25, 1437.72files/s]\u001b[A\n",
      " 83%|████████▎ | 174014/210001 [01:04<00:23, 1558.08files/s]\u001b[A\n",
      " 83%|████████▎ | 174200/210001 [01:04<00:21, 1632.08files/s]\u001b[A\n",
      " 83%|████████▎ | 174385/210001 [01:04<00:21, 1677.90files/s]\u001b[A\n",
      " 83%|████████▎ | 174569/210001 [01:04<00:21, 1674.45files/s]\u001b[A\n",
      " 83%|████████▎ | 174748/210001 [01:04<00:22, 1571.03files/s]\u001b[A\n",
      " 83%|████████▎ | 174914/210001 [01:04<00:22, 1543.44files/s]\u001b[A\n",
      " 83%|████████▎ | 175115/210001 [01:04<00:21, 1657.08files/s]\u001b[A\n",
      " 83%|████████▎ | 175323/210001 [01:04<00:19, 1760.24files/s]\u001b[A\n",
      " 84%|████████▎ | 175549/210001 [01:04<00:18, 1884.30files/s]\u001b[A\n",
      " 84%|████████▎ | 175761/210001 [01:05<00:17, 1948.20files/s]\u001b[A\n",
      " 84%|████████▍ | 176053/210001 [01:05<00:15, 2163.42files/s]\u001b[A\n",
      " 84%|████████▍ | 176374/210001 [01:05<00:14, 2396.75files/s]\u001b[A\n",
      " 84%|████████▍ | 176682/210001 [01:05<00:12, 2567.55files/s]\u001b[A\n",
      " 84%|████████▍ | 177014/210001 [01:05<00:11, 2754.00files/s]\u001b[A\n",
      " 84%|████████▍ | 177335/210001 [01:05<00:11, 2874.46files/s]\u001b[A\n",
      " 85%|████████▍ | 177634/210001 [01:05<00:14, 2192.55files/s]\u001b[A\n",
      " 85%|████████▍ | 177886/210001 [01:06<00:24, 1310.26files/s]\u001b[A\n",
      " 85%|████████▍ | 178086/210001 [01:06<00:21, 1460.74files/s]\u001b[A\n",
      " 85%|████████▍ | 178284/210001 [01:06<00:20, 1536.68files/s]\u001b[A\n",
      " 85%|████████▌ | 178529/210001 [01:06<00:18, 1729.58files/s]\u001b[A\n",
      " 85%|████████▌ | 178736/210001 [01:06<00:17, 1792.95files/s]\u001b[A\n",
      " 85%|████████▌ | 178940/210001 [01:06<00:17, 1772.45files/s]\u001b[A\n",
      " 85%|████████▌ | 179218/210001 [01:06<00:15, 1986.74files/s]\u001b[A\n",
      " 85%|████████▌ | 179470/210001 [01:06<00:14, 2120.95files/s]\u001b[A\n",
      " 86%|████████▌ | 179699/210001 [01:06<00:14, 2061.48files/s]\u001b[A\n",
      " 86%|████████▌ | 179918/210001 [01:07<00:14, 2091.97files/s]\u001b[A\n",
      " 86%|████████▌ | 180243/210001 [01:07<00:12, 2341.90files/s]\u001b[A\n",
      " 86%|████████▌ | 180533/210001 [01:07<00:11, 2482.97files/s]\u001b[A\n",
      " 86%|████████▌ | 180795/210001 [01:07<00:12, 2275.61files/s]\u001b[A\n",
      " 86%|████████▌ | 181036/210001 [01:07<00:12, 2234.80files/s]\u001b[A\n",
      " 86%|████████▋ | 181298/210001 [01:07<00:12, 2329.91files/s]\u001b[A\n",
      " 86%|████████▋ | 181542/210001 [01:07<00:12, 2359.89files/s]\u001b[A\n",
      " 87%|████████▋ | 181902/210001 [01:07<00:10, 2627.35files/s]\u001b[A\n",
      " 87%|████████▋ | 182274/210001 [01:07<00:09, 2880.09files/s]\u001b[A\n",
      " 87%|████████▋ | 182579/210001 [01:08<00:12, 2233.17files/s]\u001b[A\n",
      " 87%|████████▋ | 182837/210001 [01:08<00:15, 1714.61files/s]\u001b[A\n",
      " 87%|████████▋ | 183060/210001 [01:08<00:14, 1841.52files/s]\u001b[A\n",
      " 87%|████████▋ | 183324/210001 [01:08<00:13, 2021.10files/s]\u001b[A\n",
      " 87%|████████▋ | 183554/210001 [01:08<00:14, 1765.85files/s]\u001b[A\n",
      " 88%|████████▊ | 183756/210001 [01:08<00:19, 1377.02files/s]\u001b[A\n",
      " 88%|████████▊ | 183925/210001 [01:09<00:18, 1414.63files/s]\u001b[A\n",
      " 88%|████████▊ | 184089/210001 [01:09<00:18, 1385.03files/s]\u001b[A\n",
      " 88%|████████▊ | 184243/210001 [01:09<00:18, 1373.48files/s]\u001b[A\n",
      " 88%|████████▊ | 184392/210001 [01:09<00:19, 1309.13files/s]\u001b[A\n",
      " 88%|████████▊ | 184532/210001 [01:09<00:20, 1227.98files/s]\u001b[A\n",
      " 88%|████████▊ | 184662/210001 [01:09<00:23, 1076.85files/s]\u001b[A\n",
      " 88%|████████▊ | 184855/210001 [01:09<00:20, 1241.24files/s]\u001b[A\n",
      " 88%|████████▊ | 185054/210001 [01:09<00:17, 1398.86files/s]\u001b[A\n",
      " 88%|████████▊ | 185263/210001 [01:10<00:15, 1552.25files/s]\u001b[A\n",
      " 88%|████████▊ | 185493/210001 [01:10<00:14, 1719.98files/s]\u001b[A\n",
      " 88%|████████▊ | 185816/210001 [01:10<00:12, 2000.42files/s]\u001b[A\n",
      " 89%|████████▊ | 186160/210001 [01:10<00:10, 2287.52files/s]\u001b[A\n",
      " 89%|████████▉ | 186500/210001 [01:10<00:09, 2534.89files/s]\u001b[A\n",
      " 89%|████████▉ | 186787/210001 [01:10<00:09, 2578.32files/s]\u001b[A\n",
      " 89%|████████▉ | 187069/210001 [01:10<00:09, 2533.44files/s]\u001b[A\n",
      " 89%|████████▉ | 187339/210001 [01:10<00:09, 2346.30files/s]\u001b[A\n",
      " 89%|████████▉ | 187592/210001 [01:10<00:09, 2396.27files/s]\u001b[A\n",
      " 89%|████████▉ | 187845/210001 [01:10<00:09, 2434.56files/s]\u001b[A\n",
      " 90%|████████▉ | 188178/210001 [01:11<00:08, 2646.75files/s]\u001b[A\n",
      " 90%|████████▉ | 188505/210001 [01:11<00:07, 2805.81files/s]\u001b[A\n",
      " 90%|████████▉ | 188826/210001 [01:11<00:07, 2914.86files/s]\u001b[A\n",
      " 90%|█████████ | 189126/210001 [01:11<00:07, 2938.37files/s]\u001b[A\n",
      " 90%|█████████ | 189447/210001 [01:11<00:06, 3014.45files/s]\u001b[A\n",
      " 90%|█████████ | 189803/210001 [01:11<00:06, 3158.63files/s]\u001b[A\n",
      " 91%|█████████ | 190124/210001 [01:11<00:07, 2696.19files/s]\u001b[A\n",
      " 91%|█████████ | 190409/210001 [01:11<00:08, 2278.32files/s]\u001b[A\n",
      " 91%|█████████ | 190659/210001 [01:12<00:09, 2103.49files/s]\u001b[A\n",
      " 91%|█████████ | 190888/210001 [01:12<00:09, 1982.99files/s]\u001b[A\n",
      " 91%|█████████ | 191101/210001 [01:12<00:10, 1804.95files/s]\u001b[A\n",
      " 91%|█████████ | 191295/210001 [01:12<00:11, 1665.60files/s]\u001b[A\n",
      " 91%|█████████ | 191473/210001 [01:12<00:11, 1627.58files/s]\u001b[A\n",
      " 91%|█████████▏| 191644/210001 [01:12<00:11, 1540.70files/s]\u001b[A\n",
      " 91%|█████████▏| 191805/210001 [01:12<00:12, 1493.71files/s]\u001b[A\n",
      " 91%|█████████▏| 191960/210001 [01:12<00:12, 1440.10files/s]\u001b[A\n",
      " 91%|█████████▏| 192108/210001 [01:13<00:12, 1429.88files/s]\u001b[A\n",
      " 92%|█████████▏| 192284/210001 [01:13<00:11, 1513.64files/s]\u001b[A\n",
      " 92%|█████████▏| 192460/210001 [01:13<00:11, 1578.89files/s]\u001b[A\n",
      " 92%|█████████▏| 192626/210001 [01:13<00:11, 1545.17files/s]\u001b[A\n",
      " 92%|█████████▏| 192787/210001 [01:13<00:11, 1563.84files/s]\u001b[A\n",
      " 92%|█████████▏| 192949/210001 [01:13<00:10, 1579.56files/s]\u001b[A\n",
      " 92%|█████████▏| 193160/210001 [01:13<00:09, 1707.65files/s]\u001b[A\n",
      " 92%|█████████▏| 193335/210001 [01:13<00:10, 1570.71files/s]\u001b[A\n",
      " 92%|█████████▏| 193584/210001 [01:13<00:09, 1766.32files/s]\u001b[A\n",
      " 92%|█████████▏| 193820/210001 [01:14<00:08, 1910.25files/s]\u001b[A\n",
      " 92%|█████████▏| 194026/210001 [01:14<00:08, 1948.33files/s]\u001b[A\n",
      " 92%|█████████▏| 194250/210001 [01:14<00:07, 2027.33files/s]\u001b[A\n",
      " 93%|█████████▎| 194460/210001 [01:14<00:07, 1962.79files/s]\u001b[A\n",
      " 93%|█████████▎| 194662/210001 [01:14<00:07, 1917.60files/s]\u001b[A\n",
      " 93%|█████████▎| 194858/210001 [01:14<00:08, 1868.88files/s]\u001b[A\n",
      " 93%|█████████▎| 195048/210001 [01:14<00:08, 1798.80files/s]\u001b[A\n",
      " 93%|█████████▎| 195240/210001 [01:14<00:08, 1832.13files/s]\u001b[A\n",
      " 93%|█████████▎| 195466/210001 [01:14<00:07, 1941.32files/s]\u001b[A\n",
      " 93%|█████████▎| 195802/210001 [01:14<00:06, 2222.53files/s]\u001b[A\n",
      " 93%|█████████▎| 196143/210001 [01:15<00:05, 2481.57files/s]\u001b[A\n",
      " 94%|█████████▎| 196486/210001 [01:15<00:04, 2705.29files/s]\u001b[A\n",
      " 94%|█████████▎| 196845/210001 [01:15<00:04, 2919.77files/s]\u001b[A\n",
      " 94%|█████████▍| 197161/210001 [01:15<00:04, 2984.29files/s]\u001b[A\n",
      " 94%|█████████▍| 197474/210001 [01:15<00:04, 3016.65files/s]\u001b[A\n",
      " 94%|█████████▍| 197786/210001 [01:15<00:04, 3005.44files/s]\u001b[A\n",
      " 94%|█████████▍| 198114/210001 [01:15<00:03, 3079.17files/s]\u001b[A\n",
      " 94%|█████████▍| 198428/210001 [01:15<00:03, 3010.31files/s]\u001b[A\n",
      " 95%|█████████▍| 198743/210001 [01:15<00:03, 3049.31files/s]\u001b[A\n",
      " 95%|█████████▍| 199087/210001 [01:15<00:03, 3156.02files/s]\u001b[A\n",
      " 95%|█████████▍| 199423/210001 [01:16<00:03, 3214.45files/s]\u001b[A\n",
      " 95%|█████████▌| 199749/210001 [01:16<00:03, 3227.33files/s]\u001b[A\n",
      " 95%|█████████▌| 200074/210001 [01:16<00:03, 2977.43files/s]\u001b[A\n",
      " 95%|█████████▌| 200377/210001 [01:16<00:03, 2525.06files/s]\u001b[A\n",
      " 96%|█████████▌| 200645/210001 [01:16<00:03, 2454.11files/s]\u001b[A\n",
      " 96%|█████████▌| 200902/210001 [01:16<00:03, 2432.99files/s]\u001b[A\n",
      " 96%|█████████▌| 201154/210001 [01:16<00:04, 1860.00files/s]\u001b[A\n",
      " 96%|█████████▌| 201366/210001 [01:17<00:09, 903.47files/s] \u001b[A\n",
      " 96%|█████████▌| 201527/210001 [01:17<00:08, 968.50files/s]\u001b[A\n",
      " 96%|█████████▌| 201704/210001 [01:17<00:07, 1120.70files/s]\u001b[A\n",
      " 96%|█████████▌| 201861/210001 [01:17<00:06, 1186.87files/s]\u001b[A\n",
      " 96%|█████████▌| 202020/210001 [01:17<00:06, 1283.40files/s]\u001b[A\n",
      " 96%|█████████▋| 202306/210001 [01:17<00:05, 1536.95files/s]\u001b[A\n",
      " 96%|█████████▋| 202499/210001 [01:18<00:05, 1417.14files/s]\u001b[A\n",
      " 97%|█████████▋| 202670/210001 [01:18<00:05, 1250.84files/s]\u001b[A\n",
      " 97%|█████████▋| 202820/210001 [01:18<00:09, 734.55files/s] \u001b[A\n",
      " 97%|█████████▋| 202936/210001 [01:19<00:13, 528.05files/s]\u001b[A\n",
      " 97%|█████████▋| 203027/210001 [01:19<00:12, 566.11files/s]\u001b[A\n",
      " 97%|█████████▋| 203111/210001 [01:19<00:11, 622.19files/s]\u001b[A\n",
      " 97%|█████████▋| 203194/210001 [01:19<00:10, 659.00files/s]\u001b[A\n",
      " 97%|█████████▋| 203275/210001 [01:19<00:10, 613.60files/s]\u001b[A\n",
      " 97%|█████████▋| 203348/210001 [01:19<00:11, 584.17files/s]\u001b[A\n",
      " 97%|█████████▋| 203453/210001 [01:19<00:09, 673.75files/s]\u001b[A\n",
      " 97%|█████████▋| 203596/210001 [01:19<00:08, 800.31files/s]\u001b[A\n",
      " 97%|█████████▋| 203805/210001 [01:20<00:06, 981.56files/s]\u001b[A\n",
      " 97%|█████████▋| 203969/210001 [01:20<00:05, 1115.63files/s]\u001b[A\n",
      " 97%|█████████▋| 204199/210001 [01:20<00:04, 1318.93files/s]\u001b[A\n",
      " 97%|█████████▋| 204367/210001 [01:20<00:05, 1106.34files/s]\u001b[A\n",
      " 97%|█████████▋| 204543/210001 [01:20<00:04, 1244.53files/s]\u001b[A\n",
      " 97%|█████████▋| 204704/210001 [01:20<00:03, 1334.79files/s]\u001b[A\n",
      " 98%|█████████▊| 204873/210001 [01:20<00:03, 1421.95files/s]\u001b[A\n",
      " 98%|█████████▊| 205032/210001 [01:21<00:05, 937.96files/s] \u001b[A\n",
      " 98%|█████████▊| 205196/210001 [01:21<00:04, 1075.70files/s]\u001b[A\n",
      " 98%|█████████▊| 205334/210001 [01:21<00:04, 1121.51files/s]\u001b[A\n",
      " 98%|█████████▊| 205483/210001 [01:21<00:03, 1211.10files/s]\u001b[A\n",
      " 98%|█████████▊| 205683/210001 [01:21<00:03, 1372.99files/s]\u001b[A\n",
      " 98%|█████████▊| 205840/210001 [01:21<00:03, 1344.27files/s]\u001b[A\n",
      " 98%|█████████▊| 205989/210001 [01:21<00:02, 1376.52files/s]\u001b[A\n",
      " 98%|█████████▊| 206141/210001 [01:21<00:02, 1403.99files/s]\u001b[A\n",
      " 98%|█████████▊| 206289/210001 [01:21<00:02, 1254.75files/s]\u001b[A\n",
      " 98%|█████████▊| 206450/210001 [01:22<00:02, 1342.83files/s]\u001b[A\n",
      " 98%|█████████▊| 206592/210001 [01:22<00:02, 1296.04files/s]\u001b[A\n",
      " 98%|█████████▊| 206728/210001 [01:22<00:03, 1010.85files/s]\u001b[A\n",
      " 98%|█████████▊| 206843/210001 [01:22<00:03, 987.96files/s] \u001b[A\n",
      " 99%|█████████▊| 206952/210001 [01:22<00:03, 893.61files/s]\u001b[A\n",
      " 99%|█████████▊| 207050/210001 [01:22<00:03, 862.29files/s]\u001b[A\n",
      " 99%|█████████▊| 207152/210001 [01:22<00:03, 903.97files/s]\u001b[A\n",
      " 99%|█████████▊| 207248/210001 [01:22<00:03, 882.39files/s]\u001b[A\n",
      " 99%|█████████▊| 207340/210001 [01:23<00:03, 859.62files/s]\u001b[A\n",
      " 99%|█████████▉| 207430/210001 [01:23<00:02, 870.00files/s]\u001b[A\n",
      " 99%|█████████▉| 207552/210001 [01:23<00:02, 951.50files/s]\u001b[A\n",
      " 99%|█████████▉| 207661/210001 [01:23<00:02, 989.17files/s]\u001b[A\n",
      " 99%|█████████▉| 207788/210001 [01:23<00:02, 1059.42files/s]\u001b[A\n",
      " 99%|█████████▉| 207966/210001 [01:23<00:01, 1204.67files/s]\u001b[A\n",
      " 99%|█████████▉| 208096/210001 [01:23<00:02, 942.44files/s] \u001b[A\n",
      " 99%|█████████▉| 208206/210001 [01:23<00:02, 884.48files/s]\u001b[A\n",
      " 99%|█████████▉| 208335/210001 [01:24<00:01, 976.22files/s]\u001b[A\n",
      " 99%|█████████▉| 208513/210001 [01:24<00:01, 1128.31files/s]\u001b[A\n",
      " 99%|█████████▉| 208643/210001 [01:24<00:01, 1128.28files/s]\u001b[A\n",
      " 99%|█████████▉| 208768/210001 [01:24<00:01, 1148.35files/s]\u001b[A\n",
      " 99%|█████████▉| 208891/210001 [01:24<00:01, 1061.37files/s]\u001b[A\n",
      "100%|█████████▉| 209005/210001 [01:24<00:00, 1038.75files/s]\u001b[A\n",
      "100%|█████████▉| 209114/210001 [01:24<00:00, 926.26files/s] \u001b[A\n",
      "100%|█████████▉| 209268/210001 [01:24<00:00, 1044.23files/s]\u001b[A\n",
      "100%|█████████▉| 209434/210001 [01:24<00:00, 1172.20files/s]\u001b[A\n",
      "100%|█████████▉| 209652/210001 [01:25<00:00, 1355.63files/s]\u001b[A\n",
      "100%|█████████▉| 209864/210001 [01:25<00:00, 1509.94files/s]\u001b[A\n",
      "100%|██████████| 210001/210001 [01:25<00:00, 2464.82files/s]\u001b[A\n",
      "  0%|          | 0/10001 [00:00<?, ?files/s]\u001b[A\n",
      "  2%|▏         | 184/10001 [00:00<00:05, 1830.17files/s]\u001b[A\n",
      "  4%|▍         | 381/10001 [00:00<00:05, 1868.16files/s]\u001b[A\n",
      "  6%|▌         | 625/10001 [00:00<00:04, 2008.33files/s]\u001b[A\n",
      "  8%|▊         | 836/10001 [00:00<00:04, 2035.70files/s]\u001b[A\n",
      " 11%|█         | 1092/10001 [00:00<00:04, 2167.80files/s]\u001b[A\n",
      " 14%|█▎        | 1363/10001 [00:00<00:03, 2304.97files/s]\u001b[A\n",
      " 16%|█▋        | 1650/10001 [00:00<00:03, 2449.27files/s]\u001b[A\n",
      " 20%|█▉        | 1954/10001 [00:00<00:03, 2600.83files/s]\u001b[A\n",
      " 22%|██▏       | 2211/10001 [00:00<00:03, 2449.35files/s]\u001b[A\n",
      " 25%|██▍       | 2456/10001 [00:01<00:03, 1932.52files/s]\u001b[A\n",
      " 27%|██▋       | 2666/10001 [00:01<00:04, 1828.99files/s]\u001b[A\n",
      " 29%|██▊       | 2862/10001 [00:01<00:04, 1666.26files/s]\u001b[A\n",
      " 32%|███▏      | 3207/10001 [00:01<00:03, 1971.52files/s]\u001b[A\n",
      " 35%|███▌      | 3522/10001 [00:01<00:02, 2218.47files/s]\u001b[A\n",
      " 38%|███▊      | 3810/10001 [00:01<00:02, 2381.70files/s]\u001b[A\n",
      " 41%|████      | 4074/10001 [00:02<00:04, 1463.94files/s]\u001b[A\n",
      " 43%|████▎     | 4316/10001 [00:02<00:03, 1660.08files/s]\u001b[A\n",
      " 46%|████▌     | 4622/10001 [00:02<00:02, 1924.13files/s]\u001b[A\n",
      " 50%|████▉     | 4960/10001 [00:02<00:02, 2208.63files/s]\u001b[A\n",
      " 53%|█████▎    | 5310/10001 [00:02<00:01, 2480.96files/s]\u001b[A\n",
      " 56%|█████▌    | 5606/10001 [00:02<00:02, 2128.96files/s]\u001b[A\n",
      " 59%|█████▊    | 5861/10001 [00:02<00:01, 2159.14files/s]\u001b[A\n",
      " 62%|██████▏   | 6188/10001 [00:02<00:01, 2402.14files/s]\u001b[A\n",
      " 65%|██████▍   | 6458/10001 [00:03<00:02, 1617.65files/s]\u001b[A\n",
      " 67%|██████▋   | 6675/10001 [00:03<00:01, 1671.62files/s]\u001b[A\n",
      " 69%|██████▉   | 6883/10001 [00:03<00:01, 1775.94files/s]\u001b[A\n",
      " 71%|███████   | 7090/10001 [00:03<00:01, 1683.60files/s]\u001b[A\n",
      " 74%|███████▎  | 7370/10001 [00:03<00:01, 1909.02files/s]\u001b[A\n",
      " 76%|███████▌  | 7586/10001 [00:03<00:01, 1626.67files/s]\u001b[A\n",
      " 79%|███████▉  | 7889/10001 [00:03<00:01, 1888.55files/s]\u001b[A\n",
      " 81%|████████  | 8111/10001 [00:03<00:00, 1936.07files/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 8329/10001 [00:04<00:00, 1775.41files/s]\u001b[A\n",
      " 85%|████████▌ | 8526/10001 [00:04<00:00, 1664.41files/s]\u001b[A\n",
      " 87%|████████▋ | 8725/10001 [00:04<00:00, 1748.84files/s]\u001b[A\n",
      " 89%|████████▉ | 8938/10001 [00:04<00:00, 1847.07files/s]\u001b[A\n",
      " 92%|█████████▏| 9186/10001 [00:04<00:00, 1988.92files/s]\u001b[A\n",
      " 94%|█████████▍| 9395/10001 [00:04<00:00, 1634.40files/s]\u001b[A\n",
      " 96%|█████████▌| 9576/10001 [00:04<00:00, 1573.98files/s]\u001b[A\n",
      " 98%|█████████▊| 9807/10001 [00:04<00:00, 1738.21files/s]\u001b[A\n",
      "100%|██████████| 10001/10001 [00:05<00:00, 1988.19files/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All features and labels uncompressed.\n"
     ]
    }
   ],
   "source": [
    "def uncompress_features_labels(file):\n",
    "    \"\"\"\n",
    "    Uncompress features and labels from a zip file\n",
    "    :param file: The zip file to extract the data from\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    with ZipFile(file) as zipf:\n",
    "        # Progress Bar\n",
    "        filenames_pbar = tqdm(zipf.namelist(), unit='files')\n",
    "        \n",
    "        # Get features and labels from all files\n",
    "        for filename in filenames_pbar:\n",
    "            # Check if the file is a directory\n",
    "            if not filename.endswith('/'):\n",
    "                with zipf.open(filename) as image_file:\n",
    "                    image = Image.open(image_file)\n",
    "                    image.load()\n",
    "                    # Load image data as 1 dimensional array\n",
    "                    # We're using float32 to save on memory space\n",
    "                    feature = np.array(image, dtype=np.float32).flatten()\n",
    "\n",
    "                # Get the the letter from the filename.  This is the letter of the image.\n",
    "                label = os.path.split(filename)[1][0]\n",
    "\n",
    "                features.append(feature)\n",
    "                labels.append(label)\n",
    "    return np.array(features), np.array(labels)\n",
    "\n",
    "# Get the features and labels from the zip files\n",
    "train_features, train_labels = uncompress_features_labels('notMNIST_train.zip')\n",
    "test_features, test_labels = uncompress_features_labels('notMNIST_test.zip')\n",
    "\n",
    "# Limit the amount of data to work with a docker container\n",
    "docker_size_limit = 150000\n",
    "train_features, train_labels = resample(train_features, train_labels, n_samples=docker_size_limit)\n",
    "\n",
    "# Set flags for feature engineering.  This will prevent you from skipping an important step.\n",
    "is_features_normal = False\n",
    "is_labels_encod = False\n",
    "\n",
    "# Wait until you see that all features and labels have been uncompressed.\n",
    "print('All features and labels uncompressed.') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"image/Mean_Variance_Image.png\" style=\"height: 75%;width: 75%; position: relative; right: 5%\">\n",
    "## Problem 1\n",
    "The first problem involves normalizing the features for your training and test data.\n",
    "\n",
    "Implement Min-Max scaling in the `normalize_grayscale()` function to a range of `a=0.1` and `b=0.9`. After scaling, the values of the pixels in the input data should range from 0.1 to 0.9.\n",
    "\n",
    "Since the raw notMNIST image data is in [grayscale](https://en.wikipedia.org/wiki/Grayscale), the current values range from a min of 0 to a max of 255.\n",
    "\n",
    "Min-Max Scaling:\n",
    "$\n",
    "X'=a+{\\frac {\\left(X-X_{\\min }\\right)\\left(b-a\\right)}{X_{\\max }-X_{\\min }}}\n",
    "$\n",
    "\n",
    "*If you're having trouble solving problem 1, you can view the solution [here](https://github.com/udacity/deep-learning/blob/master/intro-to-tensorflow/intro_to_tensorflow_solution.ipynb).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed!\n"
     ]
    }
   ],
   "source": [
    "# Problem 1 - Implement Min-Max scaling for grayscale image data\n",
    "def normalize_grayscale(image_data):\n",
    "    \"\"\"\n",
    "    Normalize the image data with Min-Max scaling to a range of [0.1, 0.9]\n",
    "    :param image_data: The image data to be normalized\n",
    "    :return: Normalized image data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Min-Max scaling for grayscale image data\n",
    "    X= image_data\n",
    "    Xmin = np.amin(image_data)\n",
    "    Xmax = np.amax(image_data)\n",
    "    \n",
    "    Xscale = 0.1 + (X-Xmin)*(0.9-0.1)/(Xmax-Xmin)\n",
    "    \n",
    "    return Xscale\n",
    "\n",
    "\n",
    "### DON'T MODIFY ANYTHING BELOW ###\n",
    "# Test Cases\n",
    "np.testing.assert_array_almost_equal(\n",
    "    normalize_grayscale(np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 255])),\n",
    "    [0.1, 0.103137254902, 0.106274509804, 0.109411764706, 0.112549019608, 0.11568627451, 0.118823529412, 0.121960784314,\n",
    "     0.125098039216, 0.128235294118, 0.13137254902, 0.9],\n",
    "    decimal=3)\n",
    "np.testing.assert_array_almost_equal(\n",
    "    normalize_grayscale(np.array([0, 1, 10, 20, 30, 40, 233, 244, 254,255])),\n",
    "    [0.1, 0.103137254902, 0.13137254902, 0.162745098039, 0.194117647059, 0.225490196078, 0.830980392157, 0.865490196078,\n",
    "     0.896862745098, 0.9])\n",
    "\n",
    "if not is_features_normal:\n",
    "    train_features = normalize_grayscale(train_features)\n",
    "    test_features = normalize_grayscale(test_features)\n",
    "    is_features_normal = True\n",
    "\n",
    "print('Tests Passed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels One-Hot Encoded\n"
     ]
    }
   ],
   "source": [
    "if not is_labels_encod:\n",
    "    # Turn labels into numbers and apply One-Hot Encoding\n",
    "    encoder = LabelBinarizer()\n",
    "    encoder.fit(train_labels)\n",
    "    train_labels = encoder.transform(train_labels)\n",
    "    test_labels = encoder.transform(test_labels)\n",
    "\n",
    "    # Change to float32, so it can be multiplied against the features in TensorFlow, which are float32\n",
    "    train_labels = train_labels.astype(np.float32)\n",
    "    test_labels = test_labels.astype(np.float32)\n",
    "    is_labels_encod = True\n",
    "\n",
    "print('Labels One-Hot Encoded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features and labels randomized and split.\n"
     ]
    }
   ],
   "source": [
    "assert is_features_normal, 'You skipped the step to normalize the features'\n",
    "assert is_labels_encod, 'You skipped the step to One-Hot Encode the labels'\n",
    "\n",
    "# Get randomized datasets for training and validation\n",
    "train_features, valid_features, train_labels, valid_labels = train_test_split(\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    test_size=0.05,\n",
    "    random_state=832289)\n",
    "\n",
    "print('Training features and labels randomized and split.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cached in pickle file.\n"
     ]
    }
   ],
   "source": [
    "# Save the data for easy access\n",
    "pickle_file = 'notMNIST.pickle'\n",
    "if not os.path.isfile(pickle_file):\n",
    "    print('Saving data to pickle file...')\n",
    "    try:\n",
    "        with open('notMNIST.pickle', 'wb') as pfile:\n",
    "            pickle.dump(\n",
    "                {\n",
    "                    'train_dataset': train_features,\n",
    "                    'train_labels': train_labels,\n",
    "                    'valid_dataset': valid_features,\n",
    "                    'valid_labels': valid_labels,\n",
    "                    'test_dataset': test_features,\n",
    "                    'test_labels': test_labels,\n",
    "                },\n",
    "                pfile, pickle.HIGHEST_PROTOCOL)\n",
    "    except Exception as e:\n",
    "        print('Unable to save data to', pickle_file, ':', e)\n",
    "        raise\n",
    "\n",
    "print('Data cached in pickle file.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint\n",
    "All your progress is now saved to the pickle file.  If you need to leave and comeback to this lab, you no longer have to start from the beginning.  Just run the code block below and it will load all the data and modules required to proceed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data and modules loaded.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Load the modules\n",
    "import pickle\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reload the data\n",
    "pickle_file = 'notMNIST.pickle'\n",
    "with open(pickle_file, 'rb') as f:\n",
    "  pickle_data = pickle.load(f)\n",
    "  train_features = pickle_data['train_dataset']\n",
    "  train_labels = pickle_data['train_labels']\n",
    "  valid_features = pickle_data['valid_dataset']\n",
    "  valid_labels = pickle_data['valid_labels']\n",
    "  test_features = pickle_data['test_dataset']\n",
    "  test_labels = pickle_data['test_labels']\n",
    "  del pickle_data  # Free up memory\n",
    "\n",
    "print('Data and modules loaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Problem 2\n",
    "\n",
    "Now it's time to build a simple neural network using TensorFlow. Here, your network will be just an input layer and an output layer.\n",
    "\n",
    "<img src=\"image/network_diagram.png\" style=\"height: 40%;width: 40%; position: relative; right: 10%\">\n",
    "\n",
    "For the input here the images have been flattened into a vector of $28 \\times 28 = 784$ features. Then, we're trying to predict the image digit so there are 10 output units, one for each label. Of course, feel free to add hidden layers if you want, but this notebook is built to guide you through a single layer network. \n",
    "\n",
    "For the neural network to train on your data, you need the following <a href=\"https://www.tensorflow.org/resources/dims_types.html#data-types\">float32</a> tensors:\n",
    " - `features`\n",
    "  - Placeholder tensor for feature data (`train_features`/`valid_features`/`test_features`)\n",
    " - `labels`\n",
    "  - Placeholder tensor for label data (`train_labels`/`valid_labels`/`test_labels`)\n",
    " - `weights`\n",
    "  - Variable Tensor with random numbers from a truncated normal distribution.\n",
    "    - See <a href=\"https://www.tensorflow.org/api_docs/python/constant_op.html#truncated_normal\">`tf.truncated_normal()` documentation</a> for help.\n",
    " - `biases`\n",
    "  - Variable Tensor with all zeros.\n",
    "    - See <a href=\"https://www.tensorflow.org/api_docs/python/constant_op.html#zeros\"> `tf.zeros()` documentation</a> for help.\n",
    "\n",
    "*If you're having trouble solving problem 2, review \"TensorFlow Linear Function\" section of the class.  If that doesn't help, the solution for this problem is available [here](intro_to_tensorflow_solution.ipynb).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed!\n"
     ]
    }
   ],
   "source": [
    "# All the pixels in the image (28 * 28 = 784)\n",
    "features_count = 784\n",
    "# All the labels\n",
    "labels_count = 10\n",
    "\n",
    "# TODO: Set the features and labels tensors\n",
    "# features = \n",
    "# labels = \n",
    "features =tf.placeholder(tf.float32)\n",
    "labels= tf.placeholder(tf.float32)\n",
    "\n",
    "# TODO: Set the weights and biases tensors\n",
    "# weights = \n",
    "# biases = \n",
    "weights = tf.Variable(tf.truncated_normal([features_count, labels_count]))\n",
    "biases = tf.Variable(tf.zeros(labels_count))\n",
    "\n",
    "\n",
    "\n",
    "### DON'T MODIFY ANYTHING BELOW ###\n",
    "\n",
    "#Test Cases\n",
    "from tensorflow.python.ops.variables import Variable\n",
    "\n",
    "assert features._op.name.startswith('Placeholder'), 'features must be a placeholder'\n",
    "assert labels._op.name.startswith('Placeholder'), 'labels must be a placeholder'\n",
    "assert isinstance(weights, Variable), 'weights must be a TensorFlow variable'\n",
    "assert isinstance(biases, Variable), 'biases must be a TensorFlow variable'\n",
    "\n",
    "assert features._shape == None or (\\\n",
    "    features._shape.dims[0].value is None and\\\n",
    "    features._shape.dims[1].value in [None, 784]), 'The shape of features is incorrect'\n",
    "assert labels._shape  == None or (\\\n",
    "    labels._shape.dims[0].value is None and\\\n",
    "    labels._shape.dims[1].value in [None, 10]), 'The shape of labels is incorrect'\n",
    "assert weights._variable._shape == (784, 10), 'The shape of weights is incorrect'\n",
    "assert biases._variable._shape == (10), 'The shape of biases is incorrect'\n",
    "\n",
    "assert features._dtype == tf.float32, 'features must be type float32'\n",
    "assert labels._dtype == tf.float32, 'labels must be type float32'\n",
    "\n",
    "# Feed dicts for training, validation, and test session\n",
    "train_feed_dict = {features: train_features, labels: train_labels}\n",
    "valid_feed_dict = {features: valid_features, labels: valid_labels}\n",
    "test_feed_dict = {features: test_features, labels: test_labels}\n",
    "\n",
    "# Linear Function WX + b\n",
    "logits = tf.matmul(features, weights) + biases\n",
    "\n",
    "prediction = tf.nn.softmax(logits)\n",
    "\n",
    "# Cross entropy\n",
    "cross_entropy = -tf.reduce_sum(labels * tf.log(prediction), reduction_indices=1)\n",
    "\n",
    "# Training loss\n",
    "loss = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "# Create an operation that initializes all variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Test Cases\n",
    "with tf.Session() as session:\n",
    "    session.run(init)\n",
    "    session.run(loss, feed_dict=train_feed_dict)\n",
    "    session.run(loss, feed_dict=valid_feed_dict)\n",
    "    session.run(loss, feed_dict=test_feed_dict)\n",
    "    biases_data = session.run(biases)\n",
    "\n",
    "assert not np.count_nonzero(biases_data), 'biases must be zeros'\n",
    "\n",
    "print('Tests Passed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy function created.\n"
     ]
    }
   ],
   "source": [
    "# Determine if the predictions are correct\n",
    "is_correct_prediction = tf.equal(tf.argmax(prediction, 1), tf.argmax(labels, 1))\n",
    "# Calculate the accuracy of the predictions\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct_prediction, tf.float32))\n",
    "\n",
    "print('Accuracy function created.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"image/Learn_Rate_Tune_Image.png\" style=\"height: 70%;width: 70%\">\n",
    "## Problem 3\n",
    "Below are 2 parameter configurations for training the neural network. In each configuration, one of the parameters has multiple options. For each configuration, choose the option that gives the best acccuracy.\n",
    "\n",
    "Parameter configurations:\n",
    "\n",
    "Configuration 1\n",
    "* **Epochs:** 1\n",
    "* **Learning Rate:**\n",
    "  * 0.8\n",
    "  * 0.5\n",
    "  * 0.1\n",
    "  * 0.05\n",
    "  * 0.01\n",
    "\n",
    "Configuration 2\n",
    "* **Epochs:**\n",
    "  * 1\n",
    "  * 2\n",
    "  * 3\n",
    "  * 4\n",
    "  * 5\n",
    "* **Learning Rate:** 0.2\n",
    "\n",
    "The code will print out a Loss and Accuracy graph, so you can see how well the neural network performed.\n",
    "\n",
    "*If you're having trouble solving problem 3, you can view the solution [here](intro_to_tensorflow_solution.ipynb).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  1/5:   0%|          | 0/1005 [00:00<?, ?batches/s]\u001b[A\n",
      "Epoch  1/5:   0%|          | 1/1005 [00:00<15:02,  1.11batches/s]\u001b[A\n",
      "Epoch  1/5:   4%|▍         | 45/1005 [00:00<10:04,  1.59batches/s]\u001b[A\n",
      "Epoch  1/5:   6%|▌         | 59/1005 [00:01<07:05,  2.22batches/s]\u001b[A\n",
      "Epoch  1/5:   9%|▉         | 94/1005 [00:01<04:47,  3.17batches/s]\u001b[A\n",
      "Epoch  1/5:  11%|█         | 112/1005 [00:02<03:26,  4.32batches/s]\u001b[A\n",
      "Epoch  1/5: 100%|██████████| 1005/1005 [00:12<00:00, 83.27batches/s]\n",
      "Epoch  2/5: 100%|██████████| 1005/1005 [00:10<00:00, 98.01batches/s]\n",
      "Epoch  3/5: 100%|██████████| 1005/1005 [00:14<00:00, 67.44batches/s]\n",
      "Epoch  4/5: 100%|██████████| 1005/1005 [00:08<00:00, 117.81batches/s]\n",
      "Epoch  5/5: 100%|██████████| 1005/1005 [00:08<00:00, 116.69batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained Model Saved.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x119e8c128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained Model Saved.\n",
      "Validation accuracy at 0.7916974425315857\n"
     ]
    }
   ],
   "source": [
    "# Change if you have memory restrictions\n",
    "batch_size = 128\n",
    "\n",
    "# TODO: Find the best parameters for each configuration\n",
    "# epochs = \n",
    "# learning_rate = \n",
    "\n",
    "epochs = 5\n",
    "learning_rate =0.2\n",
    "\n",
    "### DON'T MODIFY ANYTHING BELOW ###\n",
    "# Gradient Descent\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)    \n",
    "\n",
    "# The accuracy measured against the validation set\n",
    "validation_accuracy = 0.0\n",
    "\n",
    "# Measurements use for graphing loss and accuracy\n",
    "log_batch_step = 50\n",
    "batches = []\n",
    "loss_batch = []\n",
    "train_acc_batch = []\n",
    "valid_acc_batch = []\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Create an operation that initializes all variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as session:\n",
    "    session.run(init)\n",
    "    batch_count = int(math.ceil(len(train_features)/batch_size))\n",
    "\n",
    "    for epoch_i in range(epochs):\n",
    "        \n",
    "        # Progress bar\n",
    "        batches_pbar = tqdm(range(batch_count), desc='Epoch {:>2}/{}'.format(epoch_i+1, epochs), unit='batches')\n",
    "        \n",
    "        # The training cycle\n",
    "        for batch_i in batches_pbar:\n",
    "            # Get a batch of training features and labels\n",
    "            batch_start = batch_i*batch_size\n",
    "            batch_features = train_features[batch_start:batch_start + batch_size]\n",
    "            batch_labels = train_labels[batch_start:batch_start + batch_size]\n",
    "\n",
    "            # Run optimizer and get loss\n",
    "            _, l = session.run(\n",
    "                [optimizer, loss],\n",
    "                feed_dict={features: batch_features, labels: batch_labels})\n",
    "\n",
    "            # Log every 50 batches\n",
    "            if not batch_i % log_batch_step:\n",
    "                # Calculate Training and Validation accuracy\n",
    "                training_accuracy = session.run(accuracy, feed_dict=train_feed_dict)\n",
    "                validation_accuracy = session.run(accuracy, feed_dict=valid_feed_dict)\n",
    "\n",
    "                # Log batches\n",
    "                previous_batch = batches[-1] if batches else 0\n",
    "                batches.append(log_batch_step + previous_batch)\n",
    "                loss_batch.append(l)\n",
    "                train_acc_batch.append(training_accuracy)\n",
    "                valid_acc_batch.append(validation_accuracy)\n",
    "       \n",
    "        # Check accuracy against Validation data\n",
    "        validation_accuracy = session.run(accuracy, feed_dict=valid_feed_dict)\n",
    "    saver.save(session, save_file)\n",
    "    print('Trained Model Saved.')\n",
    "\n",
    "loss_plot = plt.subplot(211)\n",
    "loss_plot.set_title('Loss')\n",
    "loss_plot.plot(batches, loss_batch, 'g')\n",
    "loss_plot.set_xlim([batches[0], batches[-1]])\n",
    "acc_plot = plt.subplot(212)\n",
    "acc_plot.set_title('Accuracy')\n",
    "acc_plot.plot(batches, train_acc_batch, 'r', label='Training Accuracy')\n",
    "acc_plot.plot(batches, valid_acc_batch, 'x', label='Validation Accuracy')\n",
    "acc_plot.set_ylim([0, 1.0])\n",
    "acc_plot.set_xlim([batches[0], batches[-1]])\n",
    "acc_plot.legend(loc=4)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('Trained Model Saved.')\n",
    "print('Validation accuracy at {}'.format(validation_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "You're going to test your model against your hold out dataset/testing data.  This will give you a good indicator of how well the model will do in the real world.  You should have a test accuracy of at least 80%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  1/5: 100%|██████████| 1005/1005 [00:02<00:00, 358.63batches/s]\n",
      "Epoch  2/5: 100%|██████████| 1005/1005 [00:01<00:00, 607.67batches/s]\n",
      "Epoch  3/5: 100%|██████████| 1005/1005 [00:02<00:00, 454.72batches/s]\n",
      "Epoch  4/5:  68%|██████▊   | 684/1005 [00:01<00:00, 418.80batches/s]"
     ]
    }
   ],
   "source": [
    "### DON'T MODIFY ANYTHING BELOW ###\n",
    "# The accuracy measured against the test set\n",
    "test_accuracy = 0.0\n",
    "\n",
    "with tf.Session() as session:\n",
    "    \n",
    "    session.run(init)\n",
    "    batch_count = int(math.ceil(len(train_features)/batch_size))\n",
    "\n",
    "    for epoch_i in range(epochs):\n",
    "        \n",
    "        # Progress bar\n",
    "        batches_pbar = tqdm(range(batch_count), desc='Epoch {:>2}/{}'.format(epoch_i+1, epochs), unit='batches')\n",
    "        \n",
    "        # The training cycle\n",
    "        for batch_i in batches_pbar:\n",
    "            # Get a batch of training features and labels\n",
    "            batch_start = batch_i*batch_size\n",
    "            batch_features = train_features[batch_start:batch_start + batch_size]\n",
    "            batch_labels = train_labels[batch_start:batch_start + batch_size]\n",
    "\n",
    "            # Run optimizer\n",
    "            _ = session.run(optimizer, feed_dict={features: batch_features, labels: batch_labels})\n",
    "\n",
    "        # Check accuracy against Test data\n",
    "        test_accuracy = session.run(accuracy, feed_dict=test_feed_dict)\n",
    "\n",
    "\n",
    "assert test_accuracy >= 0.80, 'Test accuracy at {}, should be equal to or greater than 0.80'.format(test_accuracy)\n",
    "print('Nice Job! Test Accuracy is {}'.format(test_accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_hidden_layer=256\n",
    "\n",
    "\n",
    "#Declare placeholders & Variables\n",
    "keep_prob= tf.placeholder(tf.float32)\n",
    "hidden_weights = tf.Variable(tf.truncated_normal([features_count, n_hidden_layer]))\n",
    "hidden_bias = tf.Variable(tf.zeros(n_hidden_layer))\n",
    "\n",
    "output_weights = tf.Variable(tf.truncated_normal([n_hidden_layer, labels_count]))\n",
    "output_bias = tf.Variable(tf.zeros(labels_count))\n",
    "\n",
    "# Feed dicts for training, validation, and test session\n",
    "train_feed_dict = {features: train_features, labels: train_labels, keep_prob:0.5}\n",
    "valid_feed_dict = {features: valid_features, labels: valid_labels, keep_prob:0.5}\n",
    "test_feed_dict = {features: test_features, labels: test_labels}\n",
    "\n",
    "# Hidden layer with RELU activation\n",
    "hidden_layer = tf.add(tf.matmul(features, hidden_weights),hidden_bias)\n",
    "hidden_layer = tf.nn.relu(hidden_layer)\n",
    "hidden_layer = tf.nn.dropout(hidden_layer, keep_prob)\n",
    "# Output layer with linear activation\n",
    "logits = tf.add(tf.matmul(hidden_layer, output_weights), output_bias)\n",
    "\n",
    "\n",
    "prediction = tf.nn.softmax(logits)\n",
    "\n",
    "# Cross entropy\n",
    "cross_entropy = -tf.reduce_sum(labels * tf.log(prediction), reduction_indices=1)\n",
    "\n",
    "# Training loss\n",
    "loss = tf.reduce_mean(cross_entropy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy function created.\n"
     ]
    }
   ],
   "source": [
    "# Determine if the predictions are correct\n",
    "is_correct_prediction = tf.equal(tf.argmax(prediction, 1), tf.argmax(labels, 1))\n",
    "# Calculate the accuracy of the predictions\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct_prediction, tf.float32))\n",
    "\n",
    "print('Accuracy function created.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch  1/5:   0%|          | 0/1005 [00:00<?, ?batches/s]"
     ]
    }
   ],
   "source": [
    "# Change if you have memory restrictions\n",
    "batch_size = 128\n",
    "\n",
    "# TODO: Find the best parameters for each configuration\n",
    "# epochs = \n",
    "# learning_rate = \n",
    "\n",
    "epochs = 5\n",
    "learning_rate =0.01\n",
    "\n",
    "### DON'T MODIFY ANYTHING BELOW ###\n",
    "# Gradient Descent\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)    \n",
    "\n",
    "# The accuracy measured against the validation set\n",
    "validation_accuracy = 0.0\n",
    "\n",
    "# Measurements use for graphing loss and accuracy\n",
    "log_batch_step = 50\n",
    "batches = []\n",
    "loss_batch = []\n",
    "train_acc_batch = []\n",
    "valid_acc_batch = []\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "#tf.reset_default_graph()\n",
    "# Create an operation that initializes all variables\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as session:\n",
    "    session.run(init)\n",
    "    batch_count = int(math.ceil(len(train_features)/batch_size))\n",
    "\n",
    "    for epoch_i in range(epochs):\n",
    "        \n",
    "        # Progress bar\n",
    "        batches_pbar = tqdm(range(batch_count), desc='Epoch {:>2}/{}'.format(epoch_i+1, epochs), unit='batches')\n",
    "        \n",
    "        # The training cycle\n",
    "        for batch_i in batches_pbar:\n",
    "            # Get a batch of training features and labels\n",
    "            batch_start = batch_i*batch_size\n",
    "            batch_features = train_features[batch_start:batch_start + batch_size]\n",
    "            batch_labels = train_labels[batch_start:batch_start + batch_size]\n",
    "\n",
    "            # Run optimizer and get loss\n",
    "            _, l = session.run(\n",
    "                [optimizer, loss],\n",
    "                feed_dict={features: batch_features, labels: batch_labels, keep_prob:0.5})\n",
    "\n",
    "            # Log every 50 batches\n",
    "            if not batch_i % log_batch_step:\n",
    "                # Calculate Training and Validation accuracy\n",
    "                training_accuracy = session.run(accuracy, feed_dict=train_feed_dict)\n",
    "                validation_accuracy = session.run(accuracy, feed_dict=valid_feed_dict)\n",
    "\n",
    "                # Log batches\n",
    "                previous_batch = batches[-1] if batches else 0\n",
    "                batches.append(log_batch_step + previous_batch)\n",
    "                loss_batch.append(l)\n",
    "                train_acc_batch.append(training_accuracy)\n",
    "                valid_acc_batch.append(validation_accuracy)\n",
    "       \n",
    "        # Check accuracy against Validation data\n",
    "        validation_accuracy = session.run(accuracy, feed_dict=valid_feed_dict)\n",
    "    saver.save(session, save_file)\n",
    "    print('Trained Model Saved.')\n",
    "\n",
    "loss_plot = plt.subplot(211)\n",
    "loss_plot.set_title('Loss')\n",
    "loss_plot.plot(batches, loss_batch, 'g')\n",
    "loss_plot.set_xlim([batches[0], batches[-1]])\n",
    "acc_plot = plt.subplot(212)\n",
    "acc_plot.set_title('Accuracy')\n",
    "acc_plot.plot(batches, train_acc_batch, 'r', label='Training Accuracy')\n",
    "acc_plot.plot(batches, valid_acc_batch, 'x', label='Validation Accuracy')\n",
    "acc_plot.set_ylim([0, 1.0])\n",
    "acc_plot.set_xlim([batches[0], batches[-1]])\n",
    "acc_plot.legend(loc=4)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('Trained Model Saved.')\n",
    "print('Validation accuracy at {}'.format(validation_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple layers\n",
    "Good job!  You built a one layer TensorFlow network!  However, you might want to build more than one layer.  This is deep learning after all!  In the next section, you will start to satisfy your need for more layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
